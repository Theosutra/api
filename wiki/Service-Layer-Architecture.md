# ğŸ›ï¸ Architecture Service Layer

L'architecture Service Layer de NL2SQL API v2.0.0 offre une **sÃ©paration claire des responsabilitÃ©s** et une **maintenabilitÃ© exceptionnelle**. Cette page dÃ©taille le design pattern et son implÃ©mentation.

## ğŸ¯ Vue d'Ensemble

### Qu'est-ce que le Service Layer Pattern ?

Le **Service Layer Pattern** est un pattern architectural qui :
- ğŸ—ï¸ **SÃ©pare** la logique mÃ©tier des contrÃ´leurs API
- ğŸ”„ **Centralise** les opÃ©rations complexes dans des services dÃ©diÃ©s
- ğŸ§ª **Facilite** les tests unitaires et l'injection de dÃ©pendances
- ğŸ“ˆ **AmÃ©liore** la rÃ©utilisabilitÃ© et la maintenabilitÃ©

### Architecture Globale

```mermaid
graph TB
    subgraph "ğŸŒ API Layer (FastAPI)"
        A[routes.py] --> B[models.py]
        A --> C[dependencies.py]
    end
    
    subgraph "ğŸ”§ Service Layer"
        D[TranslationService] --> E[ValidationService]
        D --> F[Cache @decorator]
    end
    
    subgraph "âš¡ Core Layer"
        G[LLMFactory] --> H[LLMProviders]
        I[EmbeddingService] --> J[VectorSearchService]
        K[PromptManager] --> L[Jinja2 Templates]
    end
    
    subgraph "ğŸ› ï¸ Utils Layer"
        M[HTTPClient] --> N[Exceptions]
        O[CacheService] --> P[ConfigService]
    end
    
    A --> D
    D --> G
    D --> I
    D --> K
    G --> M
    I --> M
```

## ğŸ”§ Services Principaux

### 1. TranslationService ğŸ¯

**RÃ´le** : Orchestrateur principal de la traduction NL2SQL

**Localisation** : `app/services/translation_service.py`

**ResponsabilitÃ©s** :
- ğŸ” Orchestration complÃ¨te du processus de traduction
- âœ… Validation des entrÃ©es utilisateur
- ğŸ§  VÃ©rification de pertinence RH via LLM
- ğŸ” Recherche vectorielle dans Pinecone
- ğŸ¤– GÃ©nÃ©ration SQL via LLM Factory
- âœ… Validation complÃ¨te (framework + sÃ©mantique)
- ğŸ’¾ Gestion du cache avec dÃ©corateur
- ğŸ“Š Formatage des rÃ©ponses enrichies

**MÃ©thode Principale** :
```python
@cache_service_method(ttl=3600, key_prefix="translation")
async def translate(
    self,
    user_query: str,
    schema_path: Optional[str] = None,
    validate: bool = True,
    explain: bool = True,
    provider: Optional[str] = None,
    model: Optional[str] = None,
    use_cache: bool = True,
    include_similar_details: bool = False,
    **kwargs
) -> Dict[str, Any]:
```

**Flux de Traitement** :
```mermaid
sequenceDiagram
    participant API as API Layer
    participant TS as TranslationService
    participant VS as ValidationService
    participant LLM as LLM Factory
    participant VC as Vector Search
    
    API->>TS: translate(query)
    TS->>VS: validate_user_input()
    TS->>LLM: check_relevance()
    TS->>VC: find_similar_queries()
    TS->>LLM: generate_sql()
    TS->>VS: validate_complete()
    TS->>LLM: explain_sql()
    TS->>API: enriched_response
```

### 2. ValidationService âœ…

**RÃ´le** : Service unifiÃ© de validation multi-niveaux

**Localisation** : `app/services/validation_service.py`

**ResponsabilitÃ©s** :
- ğŸ” **Validation Syntaxique** : Structure SQL correcte
- ğŸ›¡ï¸ **Validation SÃ©curitÃ©** : DÃ©tection opÃ©rations destructives
- ğŸ—ï¸ **Validation Framework** : Respect rÃ¨gles obligatoires
- ğŸ§  **Validation SÃ©mantique** : Correspondance via LLM
- ğŸ”§ **Correction Automatique** : Auto-fix framework compliance
- ğŸ“‹ **Suggestions** : Recommandations d'amÃ©lioration

**MÃ©thodes ClÃ©s** :
```python
async def validate_complete(
    self, 
    sql_query: str, 
    original_request: str = None,
    schema: str = None,
    auto_fix: bool = True
) -> Dict[str, Any]:

def validate_framework(self, sql_query: str) -> Tuple[bool, str, Dict]:

def fix_framework_compliance(self, sql_query: str) -> str:
```

**Pipeline de Validation** :
```mermaid
graph LR
    A[SQL Query] --> B[Syntaxe âœ“]
    B --> C[SÃ©curitÃ© âœ“]
    C --> D[Framework âœ“]
    D --> E{Conforme?}
    E -->|Non| F[Auto-Fix]
    F --> D
    E -->|Oui| G[SÃ©mantique âœ“]
    G --> H[Validated SQL]
```

## ğŸ­ Factory Pattern - LLM Management

### LLMFactory ğŸ­

**RÃ´le** : Factory pour crÃ©er et gÃ©rer les providers LLM

**Localisation** : `app/core/llm_factory.py`

**Avantages** :
- ğŸ”Œ **Abstraction** : Interface unifiÃ©e pour tous LLM
- ğŸ”„ **ExtensibilitÃ©** : Ajout facile de nouveaux providers
- ğŸª **Cache d'instances** : RÃ©utilisation des providers
- ğŸ” **Health checks** : Surveillance centralisÃ©e
- ğŸ¯ **Prompts Jinja2** : Support templates modulaires

**Providers SupportÃ©s** :
```python
_PROVIDER_CLASSES = {
    "openai": OpenAIProvider,
    "anthropic": AnthropicProvider, 
    "google": GoogleProvider
}
```

**Utilisation** :
```python
# RÃ©cupÃ©ration d'un provider
provider = await factory.get_provider("openai")

# GÃ©nÃ©ration SQL avec contexte
sql = await factory.generate_sql(
    user_query="Ã¢ge moyen collaborateurs",
    schema=schema,
    similar_queries=results,
    context={"period": "2023", "strict_mode": True}
)
```

### Providers LLM ğŸ¤–

**Interface Commune** : `BaseLLMProvider`

**ImplÃ©mentations** :
- **OpenAIProvider** : GPT-4o, GPT-4 Turbo, GPT-3.5 Turbo
- **AnthropicProvider** : Claude 3 Opus, Sonnet, Haiku
- **GoogleProvider** : Gemini Pro, Gemini 1.5 Pro/Flash

**Gestion d'Erreurs UnifiÃ©e** :
```python
try:
    result = await provider.generate_completion(messages)
except LLMAuthError:
    # ClÃ© API invalide
except LLMQuotaError:
    # Limite dÃ©passÃ©e
except LLMNetworkError:
    # ProblÃ¨me rÃ©seau - retry automatique
```

## ğŸ¯ SystÃ¨me de Prompts Jinja2

### PromptManager ğŸ“

**Innovation** : Templates modulaires et personnalisables

**Localisation** : `app/prompts/prompt_manager.py`

**FonctionnalitÃ©s** :
- ğŸ“„ **Templates** : `sql_generation.j2`, `sql_validation.j2`
- ğŸ”„ **Contexte Dynamique** : Variables adaptables
- ğŸª **Cache** : Templates compilÃ©s
- ğŸ”™ **Fallback** : Prompts par dÃ©faut si Jinja2 Ã©choue

**Exemple de Template** :
```jinja2
{% macro generate_sql_prompt(user_query, schema, similar_queries=[], context={}) %}
Tu es un expert SQL spÃ©cialisÃ© dans la traduction de langage naturel.

Question: {{ user_query }}

{% if context.period_filter %}
Contexte temporel: {{ context.period_filter }}
{% endif %}

SchÃ©ma:
{{ schema }}

{% if similar_queries %}
Exemples similaires:
{% for query in similar_queries[:3] %}
- Score: {{ "%.2f"|format(query.score) }}
  Question: "{{ query.metadata.texte_complet }}"
  SQL: {{ query.metadata.requete }}
{% endfor %}
{% endif %}

SQL:
{% endmacro %}
```

## ğŸ’¾ Cache Intelligent

### DÃ©corateur de Service ğŸ¯

**Innovation** : Cache au niveau service avec contrÃ´le granulaire

**Localisation** : `app/utils/cache_decorator.py`

**Utilisation** :
```python
@cache_service_method(ttl=3600, key_prefix="translation")
async def translate(self, user_query: str, use_cache: bool = True):
    # Logique mÃ©tier
    pass
```

**Avantages** :
- ğŸ›ï¸ **ContrÃ´le Granulaire** : `use_cache` par requÃªte
- ğŸ”‘ **ClÃ©s Intelligentes** : Hash MD5 des paramÃ¨tres
- â±ï¸ **TTL Configurable** : DurÃ©e de vie personnalisable
- ğŸš« **Fallback Gracieux** : Continue sans cache si Redis absent

## ğŸ” Recherche Vectorielle

### VectorSearchService ğŸ¯

**Innovation** : Support complet Pinecone avec objets ScoredVector

**Localisation** : `app/core/vector_search.py`

**FonctionnalitÃ©s** :
- ğŸ” **Recherche Top-K** : RequÃªtes similaires sÃ©mantiques
- âœ… **Correspondance Exacte** : Seuil configurable (0.95)
- ğŸ”„ **Normalisation MÃ©tadonnÃ©es** : CompatibilitÃ© formats
- ğŸ“Š **DÃ©tails Enrichis** : Score, texte, SQL, ID

**Pipeline de Recherche** :
```mermaid
graph LR
    A[User Query] --> B[Google Embedding]
    B --> C[Pinecone Search]
    C --> D[ScoredVector Processing]
    D --> E[Metadata Normalization]
    E --> F[Similar Queries Details]
```

**Gestion ScoredVector** :
```python
# Support des nouveaux objets Pinecone
if hasattr(match, 'score'):
    # Objet ScoredVector (nouveau format)
    score = float(match.score)
    metadata = dict(match.metadata)
    match_id = str(match.id)
elif isinstance(match, dict):
    # Dictionnaire classique (ancien format)
    score = match.get('score')
    metadata = match.get('metadata', {})
    match_id = match.get('id', '')
```

## ğŸ”— Injection de DÃ©pendances

### Pattern d'Injection ğŸ’‰

**Service Location Pattern** :
```python
# Dans routes.py
def get_translation_service() -> TranslationService:
    global _translation_service
    if _translation_service is None:
        _translation_service = TranslationService()
    return _translation_service

# Utilisation dans endpoint
@router.post("/translate")
async def translate_to_sql(request: SQLTranslationRequest):
    service = get_translation_service()
    return await service.translate(...)
```

**Avantages** :
- ğŸª **Singleton** : Une instance par service
- ğŸ§ª **TestabilitÃ©** : Injection facile de mocks
- ğŸ”„ **Lazy Loading** : Initialisation Ã  la demande
- ğŸ¯ **DÃ©couplage** : Services indÃ©pendants

## ğŸ›¡ï¸ Gestion d'Erreurs CentralisÃ©e

### Exceptions SpÃ©cialisÃ©es ğŸš¨

**HiÃ©rarchie** : `app/core/exceptions.py`

```python
NL2SQLError (base)
â”œâ”€â”€ LLMError
â”‚   â”œâ”€â”€ LLMAuthError (401)
â”‚   â”œâ”€â”€ LLMQuotaError (429)
â”‚   â””â”€â”€ LLMNetworkError (503)
â”œâ”€â”€ ValidationError (400)
â”œâ”€â”€ FrameworkError (422)
â”œâ”€â”€ EmbeddingError (500)
â”œâ”€â”€ VectorSearchError (500)
â”œâ”€â”€ CacheError (non-critical)
â””â”€â”€ SchemaError (500)
```

**Gestion dans Services** :
```python
try:
    result = await llm_service.generate_sql(...)
except LLMAuthError as e:
    logger.error(f"Auth error: {e}")
    raise HTTPException(status_code=401, detail=e.message)
except LLMNetworkError as e:
    logger.warning(f"Network error, retry: {e}")
    # Retry automatique avec backoff
```

## ğŸ“Š Avantages de l'Architecture

### ğŸ¯ MaintenabilitÃ©

| Aspect | Avant (Monolithique) | AprÃ¨s (Service Layer) |
|--------|----------------------|------------------------|
| **Logique MÃ©tier** | DispersÃ©e dans routes | CentralisÃ©e dans services |
| **Tests** | Difficiles (dÃ©pendances) | Faciles (injection) |
| **RÃ©utilisabilitÃ©** | Code dupliquÃ© | Services rÃ©utilisables |
| **Debugging** | Complexe | Logs structurÃ©s par service |

### ğŸ”§ ExtensibilitÃ©

**Ajout d'un Nouveau LLM** :
```python
# 1. CrÃ©er le provider
class MistralProvider(BaseLLMProvider):
    # ImplÃ©mentation...

# 2. Enregistrer dans la factory
_PROVIDER_CLASSES["mistral"] = MistralProvider

# 3. Aucun autre changement nÃ©cessaire !
```

**Ajout d'une Nouvelle Validation** :
```python
# Dans ValidationService
def validate_business_rules(self, sql_query: str) -> Tuple[bool, str]:
    # Nouvelle logique de validation mÃ©tier
    pass

# IntÃ©gration automatique dans validate_complete()
```

### ğŸ§ª TestabilitÃ©

**Test d'un Service** :
```python
# Test isolÃ© du TranslationService
@pytest.fixture
def mock_llm_service():
    with patch('app.services.translation_service.LLMService') as mock:
        mock.generate_sql.return_value = "SELECT ..."
        yield mock

async def test_translation_service(mock_llm_service):
    service = TranslationService()
    result = await service.translate("test query")
    
    assert result["status"] == "success"
    assert "SELECT" in result["sql"]
    mock_llm_service.generate_sql.assert_called_once()
```

**Test d'IntÃ©gration** :
```python
# Test complet API â†’ Service â†’ Core
async def test_full_translation_flow():
    response = await client.post("/api/v1/translate", json={
        "query": "Ã¢ge moyen collaborateurs"
    })
    
    assert response.status_code == 200
    data = response.json()
    assert data["framework_compliant"] is True
    assert "similar_queries_details" in data
```

## ğŸ”„ Cycle de Vie des Services

### Initialisation au DÃ©marrage ğŸš€

**Dans `app/main.py`** :
```python
@asynccontextmanager
async def lifespan(app: FastAPI):
    # === STARTUP ===
    # 1. Initialiser LLM Service
    await initialize_llm_service()
    
    # 2. Initialiser Services MÃ©tier
    validation_service = ValidationService(settings)
    translation_service = TranslationService(settings)
    
    # 3. Health Checks
    health_status = await translation_service.get_health_status()
    
    yield  # Application prÃªte
    
    # === SHUTDOWN ===
    # Nettoyage propre
    await cleanup_llm_service()
```

### Gestion des Ressources ğŸ§¹

**Pattern de Nettoyage** :
```python
class TranslationService:
    async def __aenter__(self):
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        # Nettoyage automatique
        await self.cleanup()
    
    async def cleanup(self):
        # Fermer connexions, vider caches, etc.
        pass
```

## ğŸ“ˆ MÃ©triques et Monitoring

### Health Checks HiÃ©rarchiques ğŸ¥

```python
async def get_health_status(self) -> Dict[str, Any]:
    services_status = {}
    
    # Service d'embedding
    services_status["embedding"] = await check_embedding_service()
    
    # Service Pinecone
    services_status["pinecone"] = await check_pinecone_service()
    
    # Service LLM
    services_status["llm"] = await LLMService.check_services_health()
    
    # DÃ©terminer statut global
    critical_services = ["embedding", "pinecone", "llm"]
    global_status = "ok" if all(
        services_status.get(s, {}).get("status") == "ok" 
        for s in critical_services
    ) else "error"
    
    return {"status": global_status, "services": services_status}
```

### Logs StructurÃ©s par Service ğŸ“

```python
# Format uniforme avec identification service
logger.info(
    f"Traduction terminÃ©e en {processing_time:.3f}s "
    f"(statut: {result['status']}, framework: {framework_status}, "
    f"vecteurs similaires: {similar_count})"
)

# RÃ©sultat dans les logs
2025-05-30 09:20:26 - app.services.translation_service - INFO - 
Traduction terminÃ©e en 9.524s (statut: success, framework: conforme, vecteurs similaires: 5)
```

## ğŸš€ Bonnes Pratiques

### Do's âœ…

1. **Services Stateless** : Pas d'Ã©tat partagÃ© entre requÃªtes
2. **Injection de DÃ©pendances** : Utiliser les singletons de services
3. **Gestion d'Erreurs** : Exceptions spÃ©cialisÃ©es et recovery gracieux
4. **Cache Intelligent** : DÃ©corateur avec contrÃ´le granulaire
5. **Logs StructurÃ©s** : Identifier clairement les services
6. **Health Checks** : Surveillance de tous les services dÃ©pendants

### Don'ts âŒ

1. **Logique dans Routes** : Garder les endpoints minimalistes
2. **Services CouplÃ©s** : Ã‰viter les dÃ©pendances circulaires
3. **Ã‰tat Global** : Pas de variables globales modifiables
4. **Exceptions GÃ©nÃ©riques** : Utiliser les exceptions spÃ©cialisÃ©es
5. **Logs Verbeux** : Ã‰quilibrer dÃ©tail et lisibilitÃ©

## ğŸ”® Ã‰volutions Futures

### Prochaines AmÃ©liorations ğŸš€

1. **Service Registry** : DÃ©couverte dynamique des services
2. **Circuit Breaker** : Protection contre les services dÃ©faillants
3. **Tracing DistribuÃ©** : Suivi des requÃªtes multi-services
4. **MÃ©triques AvancÃ©es** : Prometheus + Grafana
5. **Configuration Dynamique** : Rechargement sans redÃ©marrage

### ExtensibilitÃ© PrÃ©vue ğŸ“ˆ

1. **Nouveaux Providers** : Facile via Factory Pattern
2. **Services Additionnels** : Pattern Ã©tabli pour nouveaux services
3. **Middlewares de Service** : Interception et modification
4. **Plugins Modulaires** : Architecture pluggable

---

## ğŸ¯ Navigation

**PrÃ©cÃ©dent** : [Guide de DÃ©marrage Rapide](Quick-Start-Guide)  
**Suivant** : [Multi-LLM Factory](Multi-LLM-Factory)

**Voir aussi** :
- [SystÃ¨me de Prompts Jinja2](Jinja2-Prompts-System)
- [Service de Validation](Validation-Service)
- [Gestion des Erreurs](Error-Handling)

---

*L'architecture Service Layer de NL2SQL API v2.0.0 offre une base solide pour une application IA moderne, scalable et maintenable.* ğŸ—ï¸âœ¨