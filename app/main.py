import logging
import uvicorn
from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import time
import os
import asyncio

from app.config import get_settings
from app.api.routes import router
from app.security import configure_security

# Import du nouveau service LLM
from app.core.llm_service import initialize_llm_service, cleanup_llm_service

# Configuration du logger
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)

logger = logging.getLogger(__name__)
settings = get_settings()

# Cr√©er l'application FastAPI
app = FastAPI(
    title="NL2SQL API",
    description="""
    API pour traduire des requ√™tes en langage naturel en SQL.
    Utilise une combinaison de recherche vectorielle et de g√©n√©ration via LLM pour produire des requ√™tes SQL optimis√©es.
    
    Version 2.0.0 - Architecture optimis√©e avec Factory Pattern pour les LLM.
    """,
    version="2.0.0",
    docs_url="/docs",
    redoc_url="/redoc",
    openapi_url="/openapi.json"
)

# Configurer la s√©curit√© de l'application
configure_security(app)

# Inclure les routes
app.include_router(router, prefix=settings.API_PREFIX)


@app.on_event("startup")
async def startup_event():
    """
    √âv√©nements de d√©marrage de l'application.
    
    Initialise tous les services n√©cessaires au bon fonctionnement de l'API.
    """
    logger.info("üöÄ D√©marrage de NL2SQL API v2.0.0")
    
    try:
        # Initialiser le service LLM avec la nouvelle architecture
        logger.info("Initialisation du service LLM...")
        await initialize_llm_service()
        logger.info("‚úÖ Service LLM initialis√© avec succ√®s")
        
        # V√©rifier les services essentiels
        logger.info("V√©rification des services...")
        from app.core.translator import health_check
        health_status = await health_check()
        
        if health_status["status"] == "ok":
            logger.info("‚úÖ Tous les services sont op√©rationnels")
        else:
            logger.warning(f"‚ö†Ô∏è Certains services pr√©sentent des probl√®mes: {health_status}")
        
        # Afficher les providers LLM configur√©s
        from app.core.llm_service import LLMService
        configured_providers = LLMService.get_configured_providers()
        logger.info(f"üìã Providers LLM configur√©s: {configured_providers}")
        
        logger.info("üéØ API pr√™te √† recevoir des requ√™tes")
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors du d√©marrage: {e}")
        # Ne pas faire planter l'application, mais alerter
        logger.warning("L'application d√©marre malgr√© les erreurs d'initialisation")


@app.on_event("shutdown")
async def shutdown_event():
    """
    √âv√©nements d'arr√™t de l'application.
    
    Nettoie proprement toutes les ressources avant l'arr√™t.
    """
    logger.info("üõë Arr√™t de NL2SQL API")
    
    try:
        # Nettoyer le service LLM
        logger.info("Nettoyage du service LLM...")
        await cleanup_llm_service()
        logger.info("‚úÖ Service LLM nettoy√©")
        
        logger.info("‚úÖ Arr√™t propre de l'application")
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de l'arr√™t: {e}")


@app.middleware("http")
async def log_requests(request: Request, call_next):
    """
    Middleware pour journaliser les requ√™tes et mesurer leur temps d'ex√©cution.
    
    Args:
        request: L'objet Request de FastAPI
        call_next: La fonction √† appeler pour traiter la requ√™te
        
    Returns:
        La r√©ponse HTTP
    """
    start_time = time.time()
    
    # Extraire les informations de la requ√™te
    method = request.method
    url = str(request.url)
    client_host = request.client.host if request.client else "unknown"
    
    # Journaliser la requ√™te entrante (niveau DEBUG pour √©viter le spam)
    logger.debug(f"üì® {method} {url} <- {client_host}")
    
    try:
        # Traiter la requ√™te
        response = await call_next(request)
        
        # Calculer la dur√©e de traitement
        process_time = time.time() - start_time
        
        # Journaliser la r√©ponse avec niveau appropri√©
        log_level = logging.INFO if response.status_code < 400 else logging.WARNING
        status_emoji = "‚úÖ" if response.status_code < 400 else "‚ö†Ô∏è" if response.status_code < 500 else "‚ùå"
        
        logger.log(
            log_level,
            f"{status_emoji} {method} {url} -> {response.status_code} ({process_time:.3f}s)"
        )
        
        # Ajouter un en-t√™te de temps de traitement
        response.headers["X-Process-Time"] = f"{process_time:.3f}"
        response.headers["X-API-Version"] = "2.0.0"
        
        return response
    
    except Exception as e:
        # Journaliser l'erreur
        process_time = time.time() - start_time
        logger.error(f"üí• {method} {url} -> ERROR ({process_time:.3f}s): {str(e)}", exc_info=True)
        
        # Renvoyer une r√©ponse d'erreur
        return JSONResponse(
            status_code=500,
            content={
                "detail": f"Erreur interne du serveur: {str(e)}",
                "error_type": "internal_server_error",
                "request_id": id(request)  # Simple request ID pour le debugging
            },
            headers={
                "X-Process-Time": f"{process_time:.3f}",
                "X-API-Version": "2.0.0"
            }
        )


@app.get("/", tags=["info"])
async def root():
    """
    Endpoint racine qui renvoie des informations de base sur l'API.
    
    Returns:
        Informations de base sur l'API avec statistiques des providers
    """
    try:
        # R√©cup√©rer les informations sur les providers configur√©s
        from app.core.llm_service import LLMService
        configured_providers = LLMService.get_configured_providers()
        available_models = await LLMService.get_available_models()
        
        return {
            "message": "üöÄ Bienvenue sur l'API NL2SQL v2.0.0!",
            "description": "API intelligente de traduction langage naturel vers SQL",
            "version": "2.0.0",
            "architecture": "Factory Pattern optimis√©",
            "documentation": f"{settings.API_PREFIX}/docs",
            "redoc": f"{settings.API_PREFIX}/../redoc",
            "health_check": f"{settings.API_PREFIX}/health",
            "providers": {
                "configured": configured_providers,
                "default": settings.DEFAULT_PROVIDER,
                "total_models": len(available_models)
            },
            "features": [
                "Multi-LLM (OpenAI, Anthropic, Google)",
                "Recherche vectorielle s√©mantique", 
                "Framework de s√©curit√© obligatoire",
                "Cache Redis intelligent",
                "Validation avanc√©e",
                "Retry automatique avec backoff"
            ]
        }
    
    except Exception as e:
        logger.error(f"Erreur dans endpoint racine: {e}")
        return {
            "message": "üöÄ Bienvenue sur l'API NL2SQL v2.0.0!",
            "version": "2.0.0",
            "documentation": f"{settings.API_PREFIX}/docs",
            "status": "Service partiellement disponible",
            "error": "Impossible de r√©cup√©rer les informations des providers"
        }


@app.get("/metrics", tags=["monitoring"])
async def get_metrics():
    """
    Endpoint pour r√©cup√©rer les m√©triques de performance (optionnel).
    
    Returns:
        M√©triques de performance de l'API
    """
    try:
        # R√©cup√©rer les statistiques du service LLM
        health_status = await LLMService.check_services_health()
        
        # M√©triques de base
        metrics = {
            "api_version": "2.0.0",
            "llm_services": health_status,
            "timestamp": time.time()
        }
        
        # Ajouter les statistiques HTTP si disponibles
        # (pourrait √™tre √©tendu avec un syst√®me de m√©triques plus avanc√©)
        
        return metrics
    
    except Exception as e:
        logger.error(f"Erreur lors de la r√©cup√©ration des m√©triques: {e}")
        return {
            "error": "Impossible de r√©cup√©rer les m√©triques",
            "timestamp": time.time()
        }


if __name__ == "__main__":
    # R√©cup√©rer le port √† partir des variables d'environnement ou utiliser 8000 par d√©faut
    port = int(os.environ.get("PORT", 8000))
    host = os.environ.get("HOST", "0.0.0.0")
    
    # Configuration des logs pour le d√©veloppement
    log_level = "debug" if settings.DEBUG else "info"
    
    # D√©marrer le serveur
    logger.info(f"üöÄ D√©marrage du serveur NL2SQL API v2.0.0")
    logger.info(f"üì° Host: {host}:{port}")
    logger.info(f"üîß Debug: {settings.DEBUG}")
    logger.info(f"üìù Log level: {log_level}")
    
    try:
        uvicorn.run(
            "app.main:app",
            host=host,
            port=port,
            reload=settings.DEBUG,
            log_level=log_level,
            access_log=settings.DEBUG,  # Logs d'acc√®s uniquement en debug
            server_header=False,  # Cacher la version uvicorn
            date_header=False     # Pas besoin du header date
        )
    except KeyboardInterrupt:
        logger.info("üõë Arr√™t demand√© par l'utilisateur")
    except Exception as e:
        logger.error(f"üí• Erreur fatale lors du d√©marrage: {e}")
        exit(1)