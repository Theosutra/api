import asyncio
import concurrent.futures
from typing import List, Dict, Any, Optional
import logging
from pinecone import Pinecone, PodSpec

from app.config import get_settings
from app.core.exceptions import VectorSearchError  # NOUVELLE IMPORT

# Configuration du logger
logger = logging.getLogger(__name__)

# R√©cup√©rer les param√®tres de configuration
settings = get_settings()

# Client Pinecone (initialis√© de mani√®re paresseuse)
_pc = None
_index = None


def _normalize_metadata(metadata: Dict[str, Any]) -> Dict[str, Any]:
    """
    Normalise les m√©tadonn√©es pour compatibilit√© avec diff√©rents formats.
    
    Args:
        metadata: M√©tadonn√©es brutes de Pinecone
        
    Returns:
        M√©tadonn√©es normalis√©es au format attendu
    """
    normalized = metadata.copy()
    
    # Conversion requetes -> requete (support format existant)
    if 'requetes' in normalized and 'requete' not in normalized:
        normalized['requete'] = normalized['requetes']
    
    # Conversion nom -> texte_complet (support format existant)
    if 'nom' in normalized and 'texte_complet' not in normalized:
        normalized['texte_complet'] = normalized['nom']
    
    # S'assurer que les champs obligatoires existent
    if 'requete' not in normalized:
        normalized['requete'] = ''
    
    if 'texte_complet' not in normalized:
        normalized['texte_complet'] = normalized.get('description', '')[:100] + '...' if normalized.get('description') else ''
    
    return normalized


def _init_pinecone():
    """
    Initialise le client Pinecone et l'index de mani√®re paresseuse.
    Compatible avec Pinecone Serverless et Pod-based.
    
    Returns:
        L'index Pinecone initialis√©
        
    Raises:
        VectorSearchError: Si Pinecone ne peut pas √™tre initialis√©
    """
    global _pc, _index
    if _pc is None:
        try:
            if not settings.PINECONE_API_KEY:
                raise VectorSearchError("PINECONE_API_KEY manquante dans la configuration", settings.PINECONE_INDEX_NAME)
            
            if not settings.PINECONE_INDEX_NAME:
                raise VectorSearchError("PINECONE_INDEX_NAME manquant dans la configuration", None)
            
            logger.info(f"Initialisation de Pinecone avec l'index '{settings.PINECONE_INDEX_NAME}'")
            _pc = Pinecone(api_key=settings.PINECONE_API_KEY)
            
            # V√©rifier si l'index existe (compatible Serverless et Pod-based)
            try:
                indexes = _pc.list_indexes()
                index_exists = any(idx.name == settings.PINECONE_INDEX_NAME for idx in indexes)
            except Exception as e:
                logger.error(f"Erreur lors de la v√©rification des indexes: {e}")
                raise VectorSearchError(f"Impossible de v√©rifier les indexes Pinecone: {e}", settings.PINECONE_INDEX_NAME)
            
            if not index_exists:
                # L'index n'existe pas - ne pas le cr√©er automatiquement
                # car on ne conna√Æt pas le type (Serverless vs Pod-based)
                raise VectorSearchError(
                    f"L'index '{settings.PINECONE_INDEX_NAME}' n'existe pas. "
                    f"Veuillez le cr√©er manuellement ou v√©rifier le nom dans la configuration.",
                    settings.PINECONE_INDEX_NAME
                )
            
            try:
                _index = _pc.Index(settings.PINECONE_INDEX_NAME)
                logger.info(f"Index Pinecone '{settings.PINECONE_INDEX_NAME}' initialis√© avec succ√®s")
            except Exception as e:
                logger.error(f"Erreur lors de la connexion √† l'index: {e}")
                raise VectorSearchError(f"Impossible de se connecter √† l'index '{settings.PINECONE_INDEX_NAME}': {e}", settings.PINECONE_INDEX_NAME)
            
        except VectorSearchError:
            # Re-propager les erreurs VectorSearchError
            raise
        except Exception as e:
            logger.error(f"Erreur lors de l'initialisation de Pinecone: {str(e)}")
            raise VectorSearchError(f"Erreur lors de l'initialisation de Pinecone: {str(e)}", settings.PINECONE_INDEX_NAME)
    
    return _index


def _find_similar_queries_sync(query_vector: List[float], top_k: int) -> List[Dict[str, Any]]:
    """
    Version synchrone de find_similar_queries.
    Recherche les requ√™tes les plus similaires dans Pinecone.
    
    Args:
        query_vector: Vecteur d'embedding de la requ√™te
        top_k: Nombre de r√©sultats √† retourner
        
    Returns:
        Liste des requ√™tes similaires avec leurs m√©tadonn√©es
        
    Raises:
        VectorSearchError: Si erreur lors de la recherche
    """
    # Validation des param√®tres
    if not query_vector or not isinstance(query_vector, list):
        raise VectorSearchError("query_vector doit √™tre une liste non vide", settings.PINECONE_INDEX_NAME)
    
    if len(query_vector) == 0:
        raise VectorSearchError("query_vector ne peut pas √™tre vide", settings.PINECONE_INDEX_NAME)
    
    if not isinstance(top_k, int) or top_k <= 0:
        raise VectorSearchError("top_k doit √™tre un entier positif", settings.PINECONE_INDEX_NAME)
    
    if top_k > 100:  # Limite raisonnable
        logger.warning(f"top_k tr√®s √©lev√© ({top_k}), limitation √† 100")
        top_k = 100
    
    # V√©rifier que toutes les valeurs du vecteur sont valides
    try:
        for i, value in enumerate(query_vector):
            if not isinstance(value, (int, float)):
                raise VectorSearchError(f"Valeur non num√©rique √† l'index {i}: {value}", settings.PINECONE_INDEX_NAME)
            if isinstance(value, float) and (value != value or value == float('inf') or value == float('-inf')):
                raise VectorSearchError(f"Valeur invalide (NaN ou infini) √† l'index {i}: {value}", settings.PINECONE_INDEX_NAME)
    except Exception as e:
        raise VectorSearchError(f"Erreur lors de la validation du vecteur: {e}", settings.PINECONE_INDEX_NAME)
    
    index = _init_pinecone()
    
    try:
        results = index.query(
            vector=query_vector,
            top_k=top_k,
            include_metadata=True
        )
        
        matches = results.get('matches', [])
        
        # Validation des r√©sultats
        if not isinstance(matches, list):
            raise VectorSearchError("Format de r√©ponse Pinecone invalide: 'matches' n'est pas une liste", settings.PINECONE_INDEX_NAME)
        
        # ‚úÖ FIX PRINCIPAL: G√©rer les objets ScoredVector ET les dictionnaires
        valid_matches = []
        for match in matches:
            logger.debug(f"üîç Processing match type: {type(match)}")
            
            # Extraire les donn√©es selon le type de l'objet retourn√© par Pinecone
            try:
                if hasattr(match, 'score'):
                    # ‚úÖ Objet ScoredVector de Pinecone (nouveau format)
                    score = float(match.score)
                    metadata = dict(match.metadata) if hasattr(match, 'metadata') and match.metadata else {}
                    match_id = str(match.id) if hasattr(match, 'id') else ''
                    logger.debug(f"‚úÖ ScoredVector: score={score:.3f}, id={match_id}")
                elif isinstance(match, dict):
                    # ‚úÖ Dictionnaire classique (ancien format)
                    score = match.get('score')
                    metadata = match.get('metadata', {})
                    match_id = match.get('id', '')
                    logger.debug(f"‚úÖ Dict: score={score:.3f}, id={match_id}")
                else:
                    logger.warning(f"‚ùå Type de match non reconnu: {type(match)}")
                    continue
                
                # Validation du score
                if score is not None and isinstance(score, (int, float)):
                    # V√©rifier que le score est valide (pas NaN ou infini)
                    if isinstance(score, float) and (score != score or score == float('inf') or score == float('-inf')):
                        logger.warning(f"‚ùå Score invalide ignor√©: {score}")
                        continue
                    
                    # ‚úÖ NORMALISER LES M√âTADONN√âES POUR COMPATIBILIT√â
                    normalized_metadata = _normalize_metadata(metadata)
                    
                    # V√©rifier que la requ√™te SQL n'est pas vide apr√®s normalisation
                    sql_query = normalized_metadata.get('requete', '').strip()
                    if sql_query:
                        # Reconstruire le match avec la structure attendue
                        normalized_match = {
                            'score': score,
                            'metadata': normalized_metadata,
                            'id': match_id
                        }
                        valid_matches.append(normalized_match)
                        
                        # Log de succ√®s avec d√©tails
                        texte_complet = normalized_metadata.get('texte_complet', '')[:50]
                        logger.debug(f"‚úÖ Match valide: score={score:.3f}, texte='{texte_complet}...', sql_length={len(sql_query)}")
                    else:
                        logger.warning(f"‚ùå Match ignor√©: requ√™te SQL vide (score={score:.3f})")
                else:
                    logger.warning(f"‚ùå Score invalide ignor√©: {score} (type: {type(score)})")
            
            except Exception as e:
                logger.warning(f"‚ùå Erreur lors du traitement du match: {e}")
                continue
        
        logger.info(f"üîç Recherche Pinecone: {len(valid_matches)} r√©sultats valides sur {len(matches)} totaux")
        
        # Log d√©taill√© des r√©sultats pour debug
        for i, match in enumerate(valid_matches[:3]):  # Log des 3 premiers
            metadata = match['metadata']
            logger.info(f"  {i+1}. Score: {match['score']:.3f} - '{metadata.get('texte_complet', '')[:60]}...'")
        
        return valid_matches
    
    except VectorSearchError:
        # Re-propager les erreurs VectorSearchError
        raise
    except Exception as e:
        logger.error(f"Erreur lors de la recherche de requ√™tes similaires: {str(e)}")
        raise VectorSearchError(f"Erreur lors de la recherche dans Pinecone: {str(e)}", settings.PINECONE_INDEX_NAME)


async def find_similar_queries(query_vector: List[float], top_k: int = 5) -> List[Dict[str, Any]]:
    """
    Recherche les requ√™tes SQL les plus similaires dans Pinecone de mani√®re asynchrone.
    
    Args:
        query_vector: Vecteur d'embedding de la requ√™te
        top_k: Nombre de r√©sultats √† retourner (d√©faut: 5)
        
    Returns:
        Liste des requ√™tes similaires avec leurs m√©tadonn√©es
        
    Raises:
        VectorSearchError: Si erreur lors de la recherche
    """
    # Validation des param√®tres d'entr√©e
    if not query_vector or not isinstance(query_vector, list):
        raise VectorSearchError("query_vector doit √™tre une liste non vide", settings.PINECONE_INDEX_NAME)
    
    if top_k <= 0 or top_k > 100:
        raise VectorSearchError("top_k doit √™tre entre 1 et 100", settings.PINECONE_INDEX_NAME)
    
    logger.info(f"üîç Recherche des {top_k} requ√™tes les plus similaires dans Pinecone")
    
    try:
        with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
            similar_queries = await asyncio.get_event_loop().run_in_executor(
                executor, _find_similar_queries_sync, query_vector, top_k
            )
        
        logger.info(f"‚úÖ Requ√™tes similaires trouv√©es: {len(similar_queries)}")
        return similar_queries
    
    except VectorSearchError:
        # Re-propager les erreurs VectorSearchError
        raise
    except asyncio.CancelledError:
        logger.warning("Recherche de requ√™tes similaires annul√©e")
        raise VectorSearchError("Recherche annul√©e", settings.PINECONE_INDEX_NAME)
    except Exception as e:
        logger.error(f"Erreur lors de la recherche de requ√™tes similaires: {str(e)}")
        raise VectorSearchError(f"Erreur lors de la recherche de requ√™tes similaires: {str(e)}", settings.PINECONE_INDEX_NAME)


async def check_exact_match(similar_queries: List[Dict[str, Any]], threshold: float = 0.95) -> Optional[str]:
    """
    V√©rifie si l'une des requ√™tes similaires correspond exactement √† la demande.
    
    Args:
        similar_queries: Liste des requ√™tes similaires
        threshold: Seuil de similarit√© pour consid√©rer une correspondance exacte (d√©faut: 0.95)
        
    Returns:
        La requ√™te SQL correspondante si une correspondance exacte est trouv√©e, None sinon
        
    Raises:
        VectorSearchError: Si erreur lors de la v√©rification
    """
    # Validation des param√®tres
    if not isinstance(threshold, (int, float)) or threshold < 0 or threshold > 1:
        raise VectorSearchError("threshold doit √™tre un nombre entre 0 et 1", settings.PINECONE_INDEX_NAME)
    
    if not similar_queries or not isinstance(similar_queries, list):
        logger.debug("Aucune requ√™te similaire fournie pour v√©rification de correspondance exacte")
        return None
    
    if len(similar_queries) == 0:
        logger.debug("Liste de requ√™tes similaires vide")
        return None
    
    try:
        # V√©rifier si le premier r√©sultat a un score tr√®s √©lev√© (> threshold)
        top_match = similar_queries[0]
        
        if not isinstance(top_match, dict):
            logger.warning("Format de requ√™te similaire invalide")
            return None
        
        score = top_match.get('score', 0)
        
        if not isinstance(score, (int, float)):
            logger.warning(f"Score invalide dans top_match: {score}")
            return None
        
        if score > threshold:
            metadata = top_match.get('metadata', {})
            if not isinstance(metadata, dict):
                logger.warning("M√©tadonn√©es invalides dans top_match")
                return None
            
            # ‚úÖ SUPPORT DES DEUX FORMATS : 'requete' ET 'requetes'
            sql_query = metadata.get('requete') or metadata.get('requetes')
            if sql_query and isinstance(sql_query, str) and len(sql_query.strip()) > 0:
                logger.info(f"‚úÖ Correspondance exacte trouv√©e avec un score de {score:.4f}")
                return sql_query.strip()
            else:
                logger.warning("‚ùå Requ√™te SQL manquante ou vide dans la correspondance exacte")
                return None
        
        logger.debug(f"‚ùå Pas de correspondance exacte (meilleur score: {score:.4f} < {threshold})")
        return None
    
    except Exception as e:
        logger.error(f"Erreur lors de la v√©rification de correspondance exacte: {e}")
        raise VectorSearchError(f"Erreur lors de la v√©rification de correspondance exacte: {e}", settings.PINECONE_INDEX_NAME)


async def store_query(
    query_text: str, 
    query_vector: List[float], 
    sql_query: str, 
    metadata: Optional[Dict[str, Any]] = None
) -> bool:
    """
    Stocke une nouvelle requ√™te dans Pinecone avec validation des donn√©es.
    
    Args:
        query_text: Texte de la requ√™te en langage naturel
        query_vector: Vecteur d'embedding de la requ√™te
        sql_query: Requ√™te SQL correspondante
        metadata: M√©tadonn√©es suppl√©mentaires √† stocker
        
    Returns:
        True si la requ√™te a √©t√© stock√©e avec succ√®s, False sinon
        
    Raises:
        VectorSearchError: Si erreur lors du stockage
    """
    # Validation des param√®tres
    if not query_text or not isinstance(query_text, str) or len(query_text.strip()) == 0:
        raise VectorSearchError("query_text doit √™tre une cha√Æne non vide", settings.PINECONE_INDEX_NAME)
    
    if not query_vector or not isinstance(query_vector, list) or len(query_vector) == 0:
        raise VectorSearchError("query_vector doit √™tre une liste non vide", settings.PINECONE_INDEX_NAME)
    
    if not sql_query or not isinstance(sql_query, str) or len(sql_query.strip()) == 0:
        raise VectorSearchError("sql_query doit √™tre une cha√Æne non vide", settings.PINECONE_INDEX_NAME)
    
    # V√©rifier que le vecteur contient des valeurs valides
    try:
        for i, value in enumerate(query_vector):
            if not isinstance(value, (int, float)):
                raise VectorSearchError(f"Valeur non num√©rique √† l'index {i}: {value}", settings.PINECONE_INDEX_NAME)
            if isinstance(value, float) and (value != value or value == float('inf') or value == float('-inf')):
                raise VectorSearchError(f"Valeur invalide (NaN ou infini) √† l'index {i}: {value}", settings.PINECONE_INDEX_NAME)
    except Exception as e:
        raise VectorSearchError(f"Erreur lors de la validation du vecteur: {e}", settings.PINECONE_INDEX_NAME)
    
    try:
        index = _init_pinecone()
        
        # Pr√©parer les m√©tadonn√©es avec format compatible
        if metadata is None:
            metadata = {}
        
        if not isinstance(metadata, dict):
            logger.warning("M√©tadonn√©es invalides, utilisation d'un dictionnaire vide")
            metadata = {}
        
        # ‚úÖ STOCKER DANS LES DEUX FORMATS POUR COMPATIBILIT√â
        metadata.update({
            'texte_complet': query_text.strip(),
            'requete': sql_query.strip(),
            'nom': query_text.strip(),  # Format existant
            'requetes': sql_query.strip()  # Format existant
        })
        
        # G√©n√©rer un ID unique (hash du texte de la requ√™te)
        import hashlib
        query_id = hashlib.md5(query_text.encode('utf-8')).hexdigest()
        
        # Fonction synchrone pour le stockage
        def _store_sync():
            return index.upsert(
                vectors=[
                    {
                        'id': query_id,
                        'values': query_vector,
                        'metadata': metadata
                    }
                ]
            )
        
        # Ex√©cuter le stockage de mani√®re asynchrone
        with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
            await asyncio.get_event_loop().run_in_executor(executor, _store_sync)
        
        logger.info(f"‚úÖ Requ√™te stock√©e avec succ√®s dans Pinecone (ID: {query_id})")
        return True
    
    except VectorSearchError:
        # Re-propager les erreurs VectorSearchError
        raise
    except Exception as e:
        logger.error(f"Erreur lors du stockage de la requ√™te dans Pinecone: {str(e)}")
        raise VectorSearchError(f"Erreur lors du stockage dans Pinecone: {str(e)}", settings.PINECONE_INDEX_NAME)


async def check_pinecone_service() -> dict:
    """
    V√©rifie que le service Pinecone fonctionne correctement.
    Compatible avec Pinecone Serverless et Pod-based.
    
    Returns:
        Dictionnaire indiquant le statut du service
    """
    try:
        # Initialiser Pinecone
        index = _init_pinecone()
        
        # V√©rifier que l'index est accessible
        try:
            stats = index.describe_index_stats()
        except Exception as e:
            logger.error(f"Erreur lors de la r√©cup√©ration des statistiques: {e}")
            raise VectorSearchError(f"Impossible d'acc√©der aux statistiques de l'index: {e}", settings.PINECONE_INDEX_NAME)
        
        # Gestion du format Serverless (nouveau) vs Pod-based (ancien)
        total_vector_count = 0
        dimension = 0
        namespaces = {}
        
        if hasattr(stats, 'total_vector_count'):
            # Format Serverless - les valeurs sont des propri√©t√©s directes
            total_vector_count = getattr(stats, 'total_vector_count', 0)
            dimension = getattr(stats, 'dimension', 0) 
            namespaces = getattr(stats, 'namespaces', {})
        elif isinstance(stats, dict):
            # Format Pod-based - dictionnaire classique
            total_vector_count = stats.get('total_vector_count', 0)
            dimension = stats.get('dimension', 0)
            namespaces = stats.get('namespaces', {})
        else:
            # Tentative de conversion en dictionnaire
            try:
                if hasattr(stats, 'to_dict'):
                    stats_dict = stats.to_dict()
                elif hasattr(stats, '__dict__'):
                    stats_dict = stats.__dict__
                else:
                    stats_dict = {}
                
                total_vector_count = stats_dict.get('total_vector_count', 0)
                dimension = stats_dict.get('dimension', 0)
                namespaces = stats_dict.get('namespaces', {})
            except Exception:
                # Fallback - juste v√©rifier que l'index est accessible
                logger.warning(f"Format de statistiques non reconnu: {type(stats)}, mais l'index est accessible")
                total_vector_count = "unknown"
                dimension = "unknown"
                namespaces = {}
        
        return {
            "status": "ok",
            "index": settings.PINECONE_INDEX_NAME,
            "vector_count": total_vector_count,
            "dimensions": dimension,
            "namespaces": namespaces,
            "test_successful": True
        }
    
    except VectorSearchError as e:
        logger.error(f"Erreur lors de la v√©rification du service Pinecone: {e}")
        return {
            "status": "error",
            "index": settings.PINECONE_INDEX_NAME,
            "message": str(e),
            "test_successful": False
        }
    
    except Exception as e:
        logger.error(f"Erreur inattendue lors de la v√©rification du service Pinecone: {str(e)}")
        return {
            "status": "error", 
            "index": settings.PINECONE_INDEX_NAME,
            "message": f"Erreur inattendue: {str(e)}",
            "test_successful": False
        }


async def get_index_info() -> dict:
    """
    R√©cup√®re les informations d√©taill√©es de l'index Pinecone.
    
    Returns:
        Dictionnaire avec les informations de l'index
    """
    try:
        index = _init_pinecone()
        
        # R√©cup√©rer les statistiques d√©taill√©es
        stats = index.describe_index_stats()
        
        # Informations de base
        info = {
            "index_name": settings.PINECONE_INDEX_NAME,
            "total_vectors": stats.get('total_vector_count', 0),
            "dimension": stats.get('dimension', 0),
            "namespaces": stats.get('namespaces', {}),
            "environment": settings.PINECONE_ENVIRONMENT
        }
        
        return {
            "status": "ok",
            "info": info
        }
    
    except VectorSearchError as e:
        return {
            "status": "error",
            "message": str(e)
        }
    
    except Exception as e:
        logger.error(f"Erreur lors de la r√©cup√©ration des informations d'index: {e}")
        return {
            "status": "error",
            "message": f"Erreur lors de la r√©cup√©ration des informations: {e}"
        }


async def delete_query(query_id: str) -> bool:
    """
    Supprime une requ√™te de l'index Pinecone.
    
    Args:
        query_id: ID de la requ√™te √† supprimer
        
    Returns:
        True si suppression r√©ussie
        
    Raises:
        VectorSearchError: Si erreur lors de la suppression
    """
    if not query_id or not isinstance(query_id, str) or len(query_id.strip()) == 0:
        raise VectorSearchError("query_id doit √™tre une cha√Æne non vide", settings.PINECONE_INDEX_NAME)
    
    try:
        index = _init_pinecone()
        
        def _delete_sync():
            return index.delete(ids=[query_id.strip()])
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
            await asyncio.get_event_loop().run_in_executor(executor, _delete_sync)
        
        logger.info(f"Requ√™te supprim√©e avec succ√®s (ID: {query_id})")
        return True
    
    except VectorSearchError:
        raise
    except Exception as e:
        logger.error(f"Erreur lors de la suppression: {e}")
        raise VectorSearchError(f"Erreur lors de la suppression: {e}", settings.PINECONE_INDEX_NAME)


async def search_by_metadata(filter_dict: Dict[str, Any], top_k: int = 10) -> List[Dict[str, Any]]:
    """
    Recherche des vecteurs par m√©tadonn√©es.
    
    Args:
        filter_dict: Dictionnaire de filtres pour les m√©tadonn√©es
        top_k: Nombre maximum de r√©sultats
        
    Returns:
        Liste des vecteurs correspondants
        
    Raises:
        VectorSearchError: Si erreur lors de la recherche
    """
    if not isinstance(filter_dict, dict) or len(filter_dict) == 0:
        raise VectorSearchError("filter_dict doit √™tre un dictionnaire non vide", settings.PINECONE_INDEX_NAME)
    
    if not isinstance(top_k, int) or top_k <= 0 or top_k > 100:
        raise VectorSearchError("top_k doit √™tre entre 1 et 100", settings.PINECONE_INDEX_NAME)
    
    try:
        index = _init_pinecone()
        
        def _search_sync():
            # Pinecone n√©cessite un vecteur pour la recherche, on utilise un vecteur z√©ro
            # Ceci n'est qu'un exemple - en production, utiliser une vraie recherche par m√©tadonn√©es
            dummy_vector = [0.0] * 768  # Dimension par d√©faut
            return index.query(
                vector=dummy_vector,
                filter=filter_dict,
                top_k=top_k,
                include_metadata=True
            )
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
            results = await asyncio.get_event_loop().run_in_executor(executor, _search_sync)
        
        matches = results.get('matches', [])
        logger.debug(f"Recherche par m√©tadonn√©es: {len(matches)} r√©sultats trouv√©s")
        
        return matches
    
    except VectorSearchError:
        raise
    except Exception as e:
        logger.error(f"Erreur lors de la recherche par m√©tadonn√©es: {e}")
        raise VectorSearchError(f"Erreur lors de la recherche par m√©tadonn√©es: {e}", settings.PINECONE_INDEX_NAME)


async def cleanup_vector_service():
    """
    Nettoie les ressources du service de recherche vectorielle.
    Utile lors de l'arr√™t de l'application.
    """
    global _pc, _index
    try:
        if _pc is not None:
            # Pinecone ne n√©cessite pas de nettoyage sp√©cial
            _pc = None
            _index = None
            logger.info("Service de recherche vectorielle nettoy√©")
    
    except Exception as e:
        logger.warning(f"Erreur lors du nettoyage du service vectoriel: {e}")


# Fonction utilitaire pour les tests
async def test_vector_operations() -> Dict[str, bool]:
    """
    Teste les op√©rations vectorielles de base.
    
    Returns:
        Dictionnaire avec les r√©sultats des tests
    """
    results = {
        "connection": False,
        "search": False,
        "store": False
    }
    
    try:
        # Test de connexion
        health = await check_pinecone_service()
        results["connection"] = health["status"] == "ok"
        
        if results["connection"]:
            # Test de recherche avec un vecteur de test
            test_vector = [0.1] * 768
            similar = await find_similar_queries(test_vector, top_k=1)
            results["search"] = isinstance(similar, list)
            
            # Test de stockage (optionnel - comment√© pour √©viter la pollution)
            # test_stored = await store_query("test query", test_vector, "SELECT 1;")
            # results["store"] = test_stored
            results["store"] = True  # Supposer que le stockage fonctionne si la recherche fonctionne
    
    except Exception as e:
        logger.error(f"Erreur lors des tests vectoriels: {e}")
    
    return results