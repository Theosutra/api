# üöÄ NL2SQL API

<div align="center">

![NL2SQL Logo](https://img.shields.io/badge/NL2SQL-API-blue?style=for-the-badge&logo=database&logoColor=white)

[![FastAPI](https://img.shields.io/badge/FastAPI-005571?style=flat-square&logo=fastapi)](https://fastapi.tiangolo.com/)
[![Multi-LLM](https://img.shields.io/badge/Multi--LLM-OpenAI|Anthropic|Google-orange?style=flat-square)](https://openai.com/)
[![Pinecone](https://img.shields.io/badge/Pinecone-Vector_DB-black?style=flat-square)](https://www.pinecone.io/)
[![Python 3.8+](https://img.shields.io/badge/Python-3.8+-blue?style=flat-square&logo=python&logoColor=white)](https://www.python.org/)
[![Docker](https://img.shields.io/badge/Docker-Ready-2496ED?style=flat-square&logo=docker&logoColor=white)](https://www.docker.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg?style=flat-square)](https://opensource.org/licenses/MIT)

_API intelligente qui traduit vos questions en langage naturel en requ√™tes SQL optimis√©es avec recherche vectorielle s√©mantique, support multi-LLM et prompts Jinja2 modulaires_

[üöÄ Installation](#-installation) ‚Ä¢ [üíª Utilisation](#-utilisation) ‚Ä¢ [üõ°Ô∏è S√©curit√©](#%EF%B8%8F-architecture-de-s√©curit√©) ‚Ä¢ [‚öôÔ∏è Configuration](#%EF%B8%8F-configuration) ‚Ä¢ [‚ùì FAQ](#-faq)

</div>

---

## ‚ú® Fonctionnalit√©s Cl√©s

- üß† **Multi-LLM** - Support OpenAI (GPT-4o), Anthropic (Claude), Google (Gemini)
- üîç **Recherche S√©mantique** - Utilise Pinecone pour trouver des requ√™tes similaires
- üõ°Ô∏è **S√©curit√© Renforc√©e** - Framework obligatoire avec filtres utilisateur automatiques
- ‚ö° **Cache Intelligent** - Redis avec contr√¥le granulaire par requ√™te
- üìã **Validation Avanc√©e** - Service unifi√© : syntaxe, s√©curit√©, framework et s√©mantique
- üìö **Documentation Interactive** - Swagger UI et ReDoc int√©gr√©s
- üê≥ **Conteneuris√©** - D√©ploiement avec Docker et Docker Compose
- üîß **Configurable** - Variables d'environnement pour tous les param√®tres
- üìä **Monitoring** - M√©triques de performance et logs d√©taill√©s
- üéØ **Prompts Jinja2** - Templates modulaires et personnalisables avec contexte dynamique

## üèóÔ∏è Architecture

```mermaid
graph TB
    A[Requ√™te NL] --> B[Validation Entr√©e]
    B --> C[V√©rification Pertinence RH]
    C --> D[Vectorisation Google]
    D --> E{Cache Hit?}
    E -->|Oui| F[Retour Cache]
    E -->|Non| G[Recherche Pinecone]
    G --> H{Correspondance Exacte?}
    H -->|Oui| I[Validation Framework]
    H -->|Non| J[G√©n√©ration LLM + Prompts Jinja2]
    J --> K[Validation Compl√®te]
    K --> L[Correction Auto si N√©cessaire]
    L --> M[G√©n√©ration Explication]
    M --> N[Mise en Cache]
    I --> N
    N --> O[R√©ponse avec Requ√™tes Similaires]
```

## üöÄ Installation

### Pr√©requis

- Python 3.8+
- Cl√©s API pour au moins un LLM provider
- Cl√© API Pinecone
- Redis (optionnel, pour le cache)
- Docker & Docker Compose (optionnel)

### üîß Installation Standard

1. **Cloner le repository**
   ```bash
   git clone https://github.com/datasulting/nl2sql-api.git
   cd nl2sql-api
   ```

2. **Cr√©er l'environnement virtuel**
   ```bash
   python -m venv venv
   source venv/bin/activate  # Linux/macOS
   venv\Scripts\activate     # Windows
   ```

3. **Installer les d√©pendances**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configuration**
   ```bash
   cp .env.example .env
   ```
   
   √âditez `.env` avec vos cl√©s API :
   ```env
   # Obligatoire
   PINECONE_API_KEY=your_key_here
   OPENAI_API_KEY=your_key_here
   
   # Optionnel pour multi-LLM
   ANTHROPIC_API_KEY=your_key_here
   GOOGLE_API_KEY=your_key_here
   
   # Configuration base
   PINECONE_INDEX_NAME=kpi-to-sql-gemini
   DEFAULT_PROVIDER=openai
   EMBEDDING_MODEL=text-embedding-004
   EMBEDDING_PROVIDER=google
   ```

5. **Ajouter votre sch√©ma**
   ```bash
   mkdir -p app/schemas
   # Copier votre fichier de sch√©ma SQL/Markdown
   cp your-schema.md app/schemas/
   ```

6. **Lancer l'application**
   ```bash
   python -m app.main
   ```

### üê≥ Installation avec Docker

1. **Pr√©parer la configuration**
   ```bash
   git clone https://github.com/datasulting/nl2sql-api.git
   cd nl2sql-api
   cp .env.example .env
   # √âditer .env avec vos cl√©s
   ```

2. **Lancer avec Docker Compose**
   ```bash
   docker-compose up -d
   ```

L'API sera accessible sur http://localhost:8000

## üíª Utilisation

### üìñ Documentation Interactive

- **Swagger UI** : http://localhost:8000/docs
- **ReDoc** : http://localhost:8000/redoc

### üîÑ Endpoint Principal : `/api/v1/translate`

```bash
curl -X POST "http://localhost:8000/api/v1/translate" \
  -H "Content-Type: application/json" \
  -H "X-API-Key: your_api_key" \
  -d '{
    "query": "Quel est l'√¢ge moyen de mes collaborateurs ?",
    "provider": "openai",
    "model": "gpt-4o",
    "explain": true,
    "use_cache": true,
    "include_similar_details": true
  }'
```

### üìã Param√®tres Disponibles

| Param√®tre | Type | D√©faut | Description |
|-----------|------|--------|-------------|
| `query` | string | **requis** | Question en langage naturel |
| `provider` | string | `openai` | LLM √† utiliser (`openai`, `anthropic`, `google`) |
| `model` | string | auto | Mod√®le sp√©cifique (ex: `gpt-4o`, `claude-3-opus-20240229`) |
| `validate` | boolean | `true` | Valider la requ√™te SQL g√©n√©r√©e |
| `explain` | boolean | `true` | Fournir une explication |
| `use_cache` | boolean | `true` | Utiliser le cache Redis |
| `include_similar_details` | boolean | `false` | Inclure les d√©tails des vecteurs similaires |
| `schema_path` | string | auto | Chemin du sch√©ma (optionnel) |
| `user_id_placeholder` | string | `"?"` | Placeholder pour l'ID utilisateur |

### üéØ Exemples d'Utilisation

<details>
<summary><b>Exemple avec Python</b></summary>

```python
import requests

url = "http://localhost:8000/api/v1/translate"
headers = {
    "Content-Type": "application/json",
    "X-API-Key": "your_api_key"
}

# Requ√™te simple
response = requests.post(url, headers=headers, json={
    "query": "Combien d'employ√©s en CDI ?",
    "provider": "openai"
})

result = response.json()
print(f"SQL: {result['sql']}")
print(f"Explication: {result['explanation']}")

# Requ√™te avanc√©e avec d√©tails des vecteurs similaires
response = requests.post(url, headers=headers, json={
    "query": "Top 10 des salaires les plus √©lev√©s en 2023",
    "provider": "anthropic",
    "model": "claude-3-opus-20240229",
    "use_cache": False,
    "include_similar_details": True
})
```

</details>

<details>
<summary><b>R√©ponse Type avec Requ√™tes Similaires</b></summary>

```json
{
  "query": "Quel est l'√¢ge moyen de mes collaborateurs ?",
  "sql": "SELECT ROUND(AVG(TRUNCATE(b.AGE, 0)), 2) AS Age_Moyen FROM depot a INNER JOIN facts b ON a.ID = b.ID_NUMDEPOT WHERE a.ID_USER = ? AND (b.FIN_CONTRAT = 'null' OR b.FIN_CONTRAT > a.datefin); #DEPOT_a# #FACTS_b# #PERIODE#",
  "valid": true,
  "validation_message": "Validation compl√®te r√©ussie",
  "explanation": "Cette requ√™te calcule l'√¢ge moyen des collaborateurs encore en contrat.",
  "is_exact_match": false,
  "status": "success",
  "processing_time": 8.979,
  "similar_queries_details": [
    {
      "score": 0.724,
      "texte_complet": "Age moyen par √©tablissement",
      "requete": "SELECT ROUND(AVG(b.AGE), 2) FROM depot a INNER JOIN facts b...",
      "id": "gemini_load_1748246903_1381"
    }
  ],
  "framework_compliant": true,
  "from_cache": false,
  "provider": "openai",
  "model": "gpt-4o"
}
```

</details>

### üõ°Ô∏è Autres Endpoints

| Endpoint | M√©thode | Description |
|----------|---------|-------------|
| `/api/v1/health` | GET | √âtat de sant√© des services |
| `/api/v1/models` | GET | Mod√®les LLM disponibles |
| `/api/v1/schemas` | GET | Sch√©mas SQL disponibles |
| `/api/v1/validate-framework` | POST | Validation framework d'une requ√™te |
| `/api/v1/prompts/templates` | GET | Templates de prompts Jinja2 |
| `/api/v1/cache/stats` | GET | Statistiques du cache Redis |

## üõ°Ô∏è Architecture de S√©curit√©

### Framework Obligatoire

Chaque requ√™te SQL g√©n√©r√©e **DOIT OBLIGATOIREMENT** respecter :

1. **Filtre Utilisateur** : `WHERE [alias_depot].ID_USER = ?`
2. **Table DEPOT** : Toujours pr√©sente pour les autorisations multi-tenant
3. **Hashtags** : `#DEPOT_[alias]#` minimum + contextuels (#PERIODE#, #FACTS_[alias]#)
4. **Lecture Seule** : Uniquement SELECT (pas d'INSERT/UPDATE/DELETE)

### Exemple de Requ√™te Conforme

```sql
SELECT b.NOM, b.PRENOM, ROUND(AVG(b.AGE), 2) AS AGE_MOYEN
FROM depot a 
INNER JOIN facts b ON a.ID = b.ID_NUMDEPOT  
WHERE a.ID_USER = ? 
  AND (b.FIN_CONTRAT = 'null' OR b.FIN_CONTRAT > a.datefin)
  AND CONCAT(SUBSTRING(a.periode, 5, 4), SUBSTRING(a.periode, 3, 2)) IN (
    SELECT MAX(CONCAT(SUBSTRING(w.periode, 5, 4), SUBSTRING(w.periode, 3, 2)))
    FROM depot w
    WHERE w.periode IN (#PERIODE#)
    AND w.id_user = a.id_user
  )
GROUP BY b.NOM, b.PRENOM
ORDER BY AGE_MOYEN DESC;
#DEPOT_a# #FACTS_b# #PERIODE#
```

### Validation Multi-Niveaux

Le `ValidationService` effectue une validation compl√®te :

1. ‚úÖ **Validation Syntaxique** - Structure SQL correcte
2. ‚úÖ **Validation S√©curit√©** - Pas d'op√©rations destructives
3. ‚úÖ **Validation Framework** - Respect des r√®gles obligatoires
4. ‚úÖ **Validation S√©mantique** - Correspondance avec la demande (LLM)
5. ‚úÖ **Correction Automatique** - Auto-fix si framework non conforme

## ‚öôÔ∏è Configuration

### Variables d'Environnement

#### üîë API Keys (Obligatoires)

```env
PINECONE_API_KEY=your_pinecone_key
OPENAI_API_KEY=your_openai_key
ANTHROPIC_API_KEY=your_anthropic_key  # Optionnel
GOOGLE_API_KEY=your_google_key        # Optionnel
```

#### ü§ñ Configuration LLM

```env
DEFAULT_PROVIDER=openai               # openai, anthropic, google
DEFAULT_OPENAI_MODEL=gpt-4o
DEFAULT_ANTHROPIC_MODEL=claude-3-opus-20240229
DEFAULT_GOOGLE_MODEL=gemini-pro
LLM_TEMPERATURE=0.2
LLM_TIMEOUT=30
```

#### üîç Configuration Embedding et Recherche

```env
# Embedding Google (nouveau)
EMBEDDING_MODEL=text-embedding-004    # Google text-embedding-004
EMBEDDING_PROVIDER=google             # google (par d√©faut)
EMBEDDING_DIMENSIONS=768              # 768 pour text-embedding-004

# Recherche vectorielle
EXACT_MATCH_THRESHOLD=0.95            # Seuil correspondance exacte
TOP_K_RESULTS=5                       # Nombre r√©sultats similaires
SCHEMA_PATH=app/schemas/datasulting.md
```

#### üóÑÔ∏è Configuration Pinecone

```env
PINECONE_INDEX_NAME=kpi-to-sql-gemini # Nom de votre index
PINECONE_ENVIRONMENT=gcp-starter      # Environnement Pinecone
```

#### üóÑÔ∏è Configuration Cache Redis

```env
REDIS_URL=redis://localhost:6379/0
REDIS_TTL=3600                # Dur√©e cache (secondes)
CACHE_ENABLED=true
```

#### üîê Configuration S√©curit√©

```env
API_KEY=your_secret_api_key   # Authentification (optionnel)
API_KEY_NAME=X-API-Key
ALLOWED_HOSTS=["*","localhost","127.0.0.1"]
DEBUG=false
```

## üîß Architecture du Projet - Service Layer Pattern

```
nl2sql-api/
‚îú‚îÄ‚îÄ app/                      # Code source principal
‚îÇ   ‚îú‚îÄ‚îÄ api/                  # Couche API (FastAPI)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models.py         # Mod√®les Pydantic avec SimilarQueryDetail
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ routes.py         # Endpoints avec gestion d'erreurs centralis√©e
‚îÇ   ‚îú‚îÄ‚îÄ services/             # üÜï COUCHE SERVICE LAYER
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ translation_service.py  # Service principal NL2SQL
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ validation_service.py   # Service unifi√© de validation
‚îÇ   ‚îú‚îÄ‚îÄ core/                 # Couche m√©tier
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ llm_factory.py    # Factory Pattern pour Multi-LLM
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ llm_providers.py  # Providers OpenAI/Anthropic/Google
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ llm_service.py    # Service LLM unifi√©
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ embedding.py      # Google text-embedding-004
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ vector_search.py  # Pinecone avec gestion ScoredVector
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ http_client.py    # Client HTTP avec retry automatique
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ exceptions.py     # Exceptions centralis√©es
‚îÇ   ‚îú‚îÄ‚îÄ prompts/              # üÜï SYST√àME DE PROMPTS JINJA2
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ prompt_manager.py # Gestionnaire central des prompts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sql_generation.j2 # Templates de g√©n√©ration SQL
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sql_validation.j2 # Templates de validation
‚îÇ   ‚îú‚îÄ‚îÄ utils/                # Utilitaires
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cache.py          # Redis avec exceptions
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cache_decorator.py # D√©corateur @cache_service_method
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schema_loader.py  # Chargement sch√©mas
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ validators.py     # Validations (deprecated ‚Üí ValidationService)
‚îÇ   ‚îú‚îÄ‚îÄ schemas/              # Sch√©mas SQL/MD
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ datasulting.md    # Sch√©ma RH avec exemples
‚îÇ   ‚îú‚îÄ‚îÄ config.py             # Configuration Pydantic
‚îÇ   ‚îú‚îÄ‚îÄ dependencies.py       # D√©pendances FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ security.py          # Middlewares s√©curit√©
‚îÇ   ‚îî‚îÄ‚îÄ main.py              # Point d'entr√©e avec Service Layer
‚îú‚îÄ‚îÄ docker/                  # Configuration Docker
‚îú‚îÄ‚îÄ tests/                   # Tests unitaires
‚îú‚îÄ‚îÄ .env.example            # Template configuration
‚îú‚îÄ‚îÄ requirements.txt        # D√©pendances Python
‚îî‚îÄ‚îÄ README.md
```

## üîÑ Flux de Traduction Complet - Service Layer

1. **R√©ception API** : Validation requ√™te utilisateur (`routes.py`)
2. **Service de Traduction** : `TranslationService.translate()` orchestrateur principal
3. **Validation d'Entr√©e** : `ValidationService.validate_user_input()`
4. **Pertinence RH** : V√©rification via LLM Factory
5. **Cache Check** : D√©corateur `@cache_service_method`
6. **Embedding** : Google `text-embedding-004` (768 dimensions)
7. **Recherche Vectorielle** : Pinecone avec gestion `ScoredVector`
8. **Correspondance Exacte** : Seuil configurable (0.95)
9. **G√©n√©ration LLM** : Via prompts Jinja2 avec contexte dynamique
10. **Validation Compl√®te** : `ValidationService.validate_complete()`
11. **Correction Auto** : Framework compliance si n√©cessaire
12. **Explication** : G√©n√©ration via LLM avec prompts sp√©cialis√©s
13. **Cache Storage** : Stockage r√©sultat si succ√®s
14. **R√©ponse Enrichie** : Avec `similar_queries_details` et m√©tadonn√©es

## üß™ Tests

```bash
# Installation des d√©pendances de test
pip install pytest pytest-asyncio httpx

# Lancer les tests
pytest tests/ -v

# Tests avec couverture
pytest tests/ --cov=app --cov-report=html
```

## üìä Monitoring & M√©triques

### Endpoints de Monitoring

- **Health Check** : `/api/v1/health` - √âtat de tous les services
- **Service Debug** : `/api/v1/debug/service-status` (mode debug uniquement)
- **Prompts Status** : `/api/v1/prompts/health` - √âtat syst√®me Jinja2

### Logs Structur√©s - Service Layer

```python
# Exemple de log
2025-05-30 09:20:26 - app.services.translation_service - INFO - Traduction termin√©e en 9.524s (statut: success, framework: conforme, vecteurs similaires: 5)
```

### M√©triques Disponibles

- Temps de traitement par requ√™te
- Taux de cache hit/miss Redis
- Distribution par provider LLM
- Taux de conformit√© framework
- Qualit√© des vecteurs similaires (scores)

## üöÄ D√©ploiement Production

### Docker Compose (Recommand√©)

```yaml
version: '3.8'
services:
  api:
    image: nl2sql-api:latest
    environment:
      - PINECONE_API_KEY=${PINECONE_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
      - REDIS_URL=redis://redis:6379/0
      - EMBEDDING_MODEL=text-embedding-004
      - EMBEDDING_PROVIDER=google
    depends_on:
      - redis
  
  redis:
    image: redis:alpine
    command: redis-server --appendonly yes
    volumes:
      - redis-data:/data

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf

volumes:
  redis-data:
```

### Variables pour Production

```env
DEBUG=false
CACHE_ENABLED=true
METRICS_ENABLED=true
API_KEY=generate_strong_secret
ALLOWED_HOSTS=["your-domain.com","api.your-domain.com"]
EMBEDDING_MODEL=text-embedding-004
EMBEDDING_PROVIDER=google
```

## ‚ùì FAQ

<details>
<summary><b>Comment l'API √©vite-t-elle la pollution de ma base vectorielle ?</b></summary>

L'API ne stocke **JAMAIS** automatiquement de nouvelles requ√™tes dans Pinecone. Elle utilise uniquement la base existante pour la recherche s√©mantique. Le stockage peut √™tre activ√© manuellement si n√©cessaire via le param√®tre `store_result=True`.

</details>

<details>
<summary><b>Quels sont les providers LLM support√©s et leurs mod√®les ?</b></summary>

- **OpenAI** : GPT-4o, GPT-4o Mini, GPT-4 Turbo, GPT-4, GPT-3.5 Turbo
- **Anthropic** : Claude 3 Opus, Claude 3 Sonnet, Claude 3 Haiku, Claude 3.5 Sonnet
- **Google** : Gemini Pro, Gemini 1.5 Pro, Gemini 1.5 Flash

</details>

<details>
<summary><b>Comment fonctionne le nouveau syst√®me d'embedding Google ?</b></summary>

L'API utilise maintenant **Google text-embedding-004** (768 dimensions) au lieu de Sentence Transformers. Cela offre :
- Meilleure qualit√© de vectorisation
- Pas de mod√®le local √† t√©l√©charger
- Compatibilit√© avec l'√©cosyst√®me Google AI

</details>

<details>
<summary><b>Que sont les "similar_queries_details" dans la r√©ponse ?</b></summary>

C'est une nouvelle fonctionnalit√© qui retourne les d√©tails complets des 5 vecteurs les plus similaires trouv√©s dans Pinecone :
```json
"similar_queries_details": [
  {
    "score": 0.724,
    "texte_complet": "Age moyen par √©tablissement", 
    "requete": "SELECT ROUND(AVG(b.AGE), 2)...",
    "id": "gemini_load_1748246903_1381"
  }
]
```

</details>

<details>
<summary><b>Comment fonctionne le syst√®me de prompts Jinja2 ?</b></summary>

Les prompts sont maintenant modulaires et personnalisables :
1. **Templates** : `sql_generation.j2`, `sql_validation.j2`
2. **Contexte dynamique** : p√©riode, d√©partement, mode strict
3. **Macros r√©utilisables** : `system_message()`, `generate_sql_prompt()`
4. **Fallback automatique** : si Jinja2 √©choue, utilise prompts par d√©faut

</details>

<details>
<summary><b>Le cache Redis est-il obligatoire ?</b></summary>

Non, Redis est optionnel. Sans Redis :
- Les performances seront l√©g√®rement impact√©es
- Chaque requ√™te sera retrait√©e compl√®tement
- La limitation de d√©bit utilisera une m√©moire interne
- Les logs indiqueront "Redis non disponible, le cache sera d√©sactiv√©"
</details>

<details>
<summary><b>Comment personnaliser le sch√©ma de base de donn√©es ?</b></summary>

1. Cr√©ez votre fichier `.sql` ou `.md` dans `app/schemas/`
2. Modifiez `SCHEMA_PATH` dans votre `.env`
3. Red√©marrez l'application

Le sch√©ma peut √™tre en SQL standard ou en Markdown document√© avec exemples.

</details>

## üÜï Nouveaut√©s v2.0.0

### **Architecture Service Layer**
- ‚úÖ `TranslationService` : Orchestrateur principal
- ‚úÖ `ValidationService` : Validation unifi√©e 
- ‚úÖ Factory Pattern pour Multi-LLM
- ‚úÖ Exceptions centralis√©es

### **Syst√®me de Prompts Jinja2**
- ‚úÖ Templates modulaires (`sql_generation.j2`, `sql_validation.j2`)
- ‚úÖ Contexte dynamique (p√©riode, d√©partement, mode strict)
- ‚úÖ Fallback automatique vers prompts par d√©faut

### **Embedding Google**
- ‚úÖ `text-embedding-004` (768 dimensions)
- ‚úÖ Plus de d√©pendance Sentence Transformers
- ‚úÖ Meilleure qualit√© de vectorisation

### **Recherche Vectorielle Am√©lior√©e**
- ‚úÖ Support objets `ScoredVector` de Pinecone
- ‚úÖ `similar_queries_details` avec score, texte complet, requ√™te SQL et ID
- ‚úÖ Normalisation automatique des m√©tadonn√©es

### **Cache et Performance**
- ‚úÖ D√©corateur `@cache_service_method` pour services
- ‚úÖ Contr√¥le granulaire par requ√™te (`use_cache`)
- ‚úÖ M√©triques de performance d√©taill√©es

## ü§ù Contribution

Les contributions sont bienvenues ! Voir [CONTRIBUTING.md](CONTRIBUTING.md) pour les guidelines.

## üìÑ Licence

Ce projet est sous licence MIT. Voir [LICENSE](LICENSE) pour plus de d√©tails.

## üìû Support

- **Organisation** : [Datasulting](https://datasulting.com)
- **Email** : support@datasulting.com
- **Documentation** : [Wiki du projet](../../wiki)

---

<div align="center">
<p>‚ú® <strong>NL2SQL API v2.0.0 - Architecture Service Layer avec Prompts Jinja2</strong> ‚ú®</p>
<p>D√©velopp√© avec ‚ù§Ô∏è par <a href="https://datasulting.com">Datasulting</a></p>
<p><em>Version 2.0.0 - Service Layer + Multi-LLM + Prompts Modulaires + Google Embedding</em></p>
</div>