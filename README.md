# ğŸš€ NL2SQL API

<div align="center">

![NL2SQL Logo](https://img.shields.io/badge/NL2SQL-API-blue?style=for-the-badge&logo=database&logoColor=white)

[![FastAPI](https://img.shields.io/badge/FastAPI-005571?style=flat-square&logo=fastapi)](https://fastapi.tiangolo.com/)
[![Multi-LLM](https://img.shields.io/badge/Multi--LLM-OpenAI|Anthropic|Google-orange?style=flat-square)](https://openai.com/)
[![Pinecone](https://img.shields.io/badge/Pinecone-Vector_DB-black?style=flat-square)](https://www.pinecone.io/)
[![Python 3.8+](https://img.shields.io/badge/Python-3.8+-blue?style=flat-square&logo=python&logoColor=white)](https://www.python.org/)
[![Docker](https://img.shields.io/badge/Docker-Ready-2496ED?style=flat-square&logo=docker&logoColor=white)](https://www.docker.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg?style=flat-square)](https://opensource.org/licenses/MIT)

_API intelligente qui traduit vos questions en langage naturel en requÃªtes SQL optimisÃ©es avec recherche vectorielle sÃ©mantique et support multi-LLM_

[ğŸš€ Installation](#-installation) â€¢ [ğŸ’» Utilisation](#-utilisation) â€¢ [ğŸ›¡ï¸ SÃ©curitÃ©](#%EF%B8%8F-architecture-de-sÃ©curitÃ©) â€¢ [âš™ï¸ Configuration](#%EF%B8%8F-configuration) â€¢ [â“ FAQ](#-faq)

</div>

---

## âœ¨ FonctionnalitÃ©s ClÃ©s

- ğŸ§  **Multi-LLM** - Support OpenAI (GPT-4), Anthropic (Claude), Google (Gemini)
- ğŸ” **Recherche SÃ©mantique** - Utilise Pinecone pour trouver des requÃªtes similaires
- ğŸ›¡ï¸ **SÃ©curitÃ© RenforcÃ©e** - Framework obligatoire avec filtres utilisateur automatiques
- âš¡ **Cache Intelligent** - Redis avec contrÃ´le granulaire par requÃªte
- ğŸ“‹ **Validation AvancÃ©e** - VÃ©rification de syntaxe, sÃ©curitÃ© et conformitÃ©
- ğŸ“š **Documentation Interactive** - Swagger UI et ReDoc intÃ©grÃ©s
- ğŸ³ **ConteneurisÃ©** - DÃ©ploiement avec Docker et Docker Compose
- ğŸ”§ **Configurable** - Variables d'environnement pour tous les paramÃ¨tres
- ğŸ“Š **Monitoring** - MÃ©triques de performance et logs dÃ©taillÃ©s

## ğŸ—ï¸ Architecture

```mermaid
graph TB
    A[RequÃªte NL] --> B[VÃ©rification Pertinence]
    B --> C[Vectorisation]
    C --> D{Cache Hit?}
    D -->|Oui| E[Retour Cache]
    D -->|Non| F[Recherche Pinecone]
    F --> G{Match Exact?}
    G -->|Oui| H[Validation Framework]
    G -->|Non| I[GÃ©nÃ©ration LLM]
    I --> J[Validation SÃ©curitÃ©]
    H --> K[RÃ©ponse]
    J --> K
    K --> L[Mise en Cache]
```

## ğŸš€ Installation

### PrÃ©requis

- Python 3.8+
- ClÃ©s API pour au moins un LLM provider
- ClÃ© API Pinecone
- Redis (optionnel, pour le cache)
- Docker & Docker Compose (optionnel)

### ğŸ”§ Installation Standard

1. **Cloner le repository**
   ```bash
   git clone https://github.com/datasulting/nl2sql-api.git
   cd nl2sql-api
   ```

2. **CrÃ©er l'environnement virtuel**
   ```bash
   python -m venv venv
   source venv/bin/activate  # Linux/macOS
   venv\Scripts\activate     # Windows
   ```

3. **Installer les dÃ©pendances**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configuration**
   ```bash
   cp .env.example .env
   ```
   
   Ã‰ditez `.env` avec vos clÃ©s API :
   ```env
   # Obligatoire
   PINECONE_API_KEY=your_key_here
   OPENAI_API_KEY=your_key_here
   
   # Optionnel pour multi-LLM
   ANTHROPIC_API_KEY=your_key_here
   GOOGLE_API_KEY=your_key_here
   
   # Configuration base
   PINECONE_INDEX_NAME=nl2sql-index
   DEFAULT_PROVIDER=openai
   ```

5. **Ajouter votre schÃ©ma**
   ```bash
   mkdir -p app/schemas
   # Copier votre fichier de schÃ©ma SQL/Markdown
   cp your-schema.sql app/schemas/
   ```

6. **Lancer l'application**
   ```bash
   python -m app.main
   ```

### ğŸ³ Installation avec Docker

1. **PrÃ©parer la configuration**
   ```bash
   git clone https://github.com/datasulting/nl2sql-api.git
   cd nl2sql-api
   cp .env.example .env
   # Ã‰diter .env avec vos clÃ©s
   ```

2. **Lancer avec Docker Compose**
   ```bash
   docker-compose up -d
   ```

L'API sera accessible sur http://localhost:8000

## ğŸ’» Utilisation

### ğŸ“– Documentation Interactive

- **Swagger UI** : http://localhost:8000/docs
- **ReDoc** : http://localhost:8000/redoc

### ğŸ”„ Endpoint Principal : `/api/v1/translate`

```bash
curl -X POST "http://localhost:8000/api/v1/translate" \
  -H "Content-Type: application/json" \
  -H "X-API-Key: your_api_key" \
  -d '{
    "query": "Liste des employÃ©s en CDI embauchÃ©s en 2023",
    "provider": "openai",
    "model": "gpt-4o",
    "explain": true,
    "use_cache": true
  }'
```

### ğŸ“‹ ParamÃ¨tres Disponibles

| ParamÃ¨tre | Type | DÃ©faut | Description |
|-----------|------|--------|-------------|
| `query` | string | **requis** | Question en langage naturel |
| `provider` | string | `openai` | LLM Ã  utiliser (`openai`, `anthropic`, `google`) |
| `model` | string | auto | ModÃ¨le spÃ©cifique (ex: `gpt-4o`, `claude-3-opus-20240229`) |
| `validate` | boolean | `true` | Valider la requÃªte SQL gÃ©nÃ©rÃ©e |
| `explain` | boolean | `true` | Fournir une explication |
| `use_cache` | boolean | `true` | Utiliser le cache Redis |
| `include_similar_details` | boolean | `false` | Inclure les dÃ©tails des vecteurs similaires |

### ğŸ¯ Exemples d'Utilisation

<details>
<summary><b>Exemple avec Python</b></summary>

```python
import requests

url = "http://localhost:8000/api/v1/translate"
headers = {
    "Content-Type": "application/json",
    "X-API-Key": "your_api_key"
}

# RequÃªte simple
response = requests.post(url, headers=headers, json={
    "query": "Combien d'employÃ©s en CDI ?",
    "provider": "openai"
})

result = response.json()
print(f"SQL: {result['sql']}")
print(f"Explication: {result['explanation']}")

# RequÃªte avancÃ©e avec cache dÃ©sactivÃ©
response = requests.post(url, headers=headers, json={
    "query": "Top 10 des salaires les plus Ã©levÃ©s en 2023",
    "provider": "anthropic",
    "model": "claude-3-opus-20240229",
    "use_cache": False,
    "include_similar_details": True
})
```

</details>

<details>
<summary><b>RÃ©ponse Type</b></summary>

```json
{
  "query": "Liste des employÃ©s en CDI embauchÃ©s en 2023",
  "sql": "SELECT f.NOM, f.PRENOM, f.DEBUT_CONTRAT\nFROM FACTS f\nJOIN DEPOT d ON f.ID_NUMDEPOT = d.ID\nWHERE d.ID_USER = ?\n  AND f.NATURE_CONTRAT = '01'\n  AND YEAR(f.DEBUT_CONTRAT) = 2023\nORDER BY f.NOM; #DEPOT_d# #FACTS_f# #PERIODE#",
  "valid": true,
  "validation_message": "RequÃªte SQL conforme au framework de sÃ©curitÃ©",
  "explanation": "Cette requÃªte liste tous les employÃ©s en CDI embauchÃ©s en 2023.",
  "is_exact_match": false,
  "status": "success",
  "processing_time": 1.84,
  "framework_compliant": true,
  "from_cache": false,
  "provider": "openai",
  "model": "gpt-4o"
}
```

</details>

### ğŸ›¡ï¸ Autres Endpoints

| Endpoint | MÃ©thode | Description |
|----------|---------|-------------|
| `/api/v1/health` | GET | Ã‰tat de santÃ© des services |
| `/api/v1/models` | GET | ModÃ¨les LLM disponibles |
| `/api/v1/schemas` | GET | SchÃ©mas SQL disponibles |
| `/api/v1/validate-framework` | POST | Validation framework d'une requÃªte |

## ğŸ›¡ï¸ Architecture de SÃ©curitÃ©

### Framework Obligatoire

Chaque requÃªte SQL gÃ©nÃ©rÃ©e **DOIT OBLIGATOIREMENT** respecter :

1. **Filtre Utilisateur** : `WHERE [alias_depot].ID_USER = ?`
2. **Table DEPOT** : Toujours prÃ©sente pour les autorisations
3. **Hashtags** : `#DEPOT_[alias]#` minimum + contextuels

### Exemple de RequÃªte Conforme

```sql
SELECT f.NOM, f.PRENOM, f.MNT_BRUT
FROM FACTS f
JOIN DEPOT d ON f.ID_NUMDEPOT = d.ID  
WHERE d.ID_USER = ? 
  AND f.NATURE_CONTRAT = '01'
ORDER BY f.NOM; #DEPOT_d# #FACTS_f#
```

### Validation Multi-Niveaux

1. âœ… **Validation Framework** - Respect des rÃ¨gles obligatoires
2. âœ… **Validation SÃ©curitÃ©** - DÃ©tection d'opÃ©rations dangereuses
3. âœ… **Validation SÃ©mantique** - CohÃ©rence avec la demande
4. âœ… **Validation SQL** - Syntaxe et structure

## âš™ï¸ Configuration

### Variables d'Environnement

#### ğŸ”‘ API Keys (Obligatoires)

```env
PINECONE_API_KEY=your_pinecone_key
OPENAI_API_KEY=your_openai_key
ANTHROPIC_API_KEY=your_anthropic_key  # Optionnel
GOOGLE_API_KEY=your_google_key        # Optionnel
```

#### ğŸ¤– Configuration LLM

```env
DEFAULT_PROVIDER=openai               # openai, anthropic, google
DEFAULT_OPENAI_MODEL=gpt-4o
DEFAULT_ANTHROPIC_MODEL=claude-3-opus-20240229
DEFAULT_GOOGLE_MODEL=gemini-pro
LLM_TEMPERATURE=0.2
LLM_TIMEOUT=30
```

#### ğŸ” Configuration Recherche

```env
EXACT_MATCH_THRESHOLD=0.95    # Seuil correspondance exacte
TOP_K_RESULTS=5               # Nombre rÃ©sultats similaires
SCHEMA_PATH=app/schemas/datasulting.sql
EMBEDDING_MODEL=all-mpnet-base-v2
```

#### ğŸ—„ï¸ Configuration Cache Redis

```env
REDIS_URL=redis://localhost:6379/0
REDIS_TTL=3600                # DurÃ©e cache (secondes)
CACHE_ENABLED=true
```

#### ğŸ” Configuration SÃ©curitÃ©

```env
API_KEY=your_secret_api_key   # Authentification (optionnel)
API_KEY_NAME=X-API-Key
ALLOWED_HOSTS=["*","localhost","127.0.0.1"]
DEBUG=false
```

## ğŸ”§ Architecture du Projet

```
nl2sql-api/
â”œâ”€â”€ app/                      # Code source principal
â”‚   â”œâ”€â”€ api/                  # Couche API
â”‚   â”‚   â”œâ”€â”€ models.py         # ModÃ¨les Pydantic
â”‚   â”‚   â””â”€â”€ routes.py         # Endpoints FastAPI
â”‚   â”œâ”€â”€ core/                 # Logique mÃ©tier
â”‚   â”‚   â”œâ”€â”€ translator.py     # Traducteur principal
â”‚   â”‚   â”œâ”€â”€ llm_service.py    # Service LLM unifiÃ©
â”‚   â”‚   â”œâ”€â”€ embedding.py      # Vectorisation
â”‚   â”‚   â””â”€â”€ vector_search.py  # Recherche Pinecone
â”‚   â”œâ”€â”€ utils/                # Utilitaires
â”‚   â”‚   â”œâ”€â”€ cache.py          # Gestion cache Redis
â”‚   â”‚   â”œâ”€â”€ validators.py     # Validations
â”‚   â”‚   â””â”€â”€ simple_framework_check.py # Framework obligatoire
â”‚   â”œâ”€â”€ schemas/              # SchÃ©mas SQL/MD
â”‚   â”œâ”€â”€ config.py             # Configuration
â”‚   â”œâ”€â”€ dependencies.py       # DÃ©pendances FastAPI
â”‚   â”œâ”€â”€ security.py          # Middlewares sÃ©curitÃ©
â”‚   â””â”€â”€ main.py              # Point d'entrÃ©e
â”œâ”€â”€ docker/                  # Configuration Docker
â”œâ”€â”€ tests/                   # Tests
â”œâ”€â”€ .env.example            # Template configuration
â”œâ”€â”€ requirements.txt        # DÃ©pendances Python
â””â”€â”€ README.md
```

## ğŸ”„ Flux de Traitement

1. **RÃ©ception** : Validation requÃªte utilisateur
2. **Pertinence** : VÃ©rification domaine RH avec LLM
3. **Cache** : Recherche en cache Redis (si activÃ©)
4. **Vectorisation** : Conversion texte â†’ vecteur
5. **Recherche** : Top-K requÃªtes similaires (Pinecone)
6. **Correspondance** : VÃ©rification correspondance exacte
7. **GÃ©nÃ©ration** : CrÃ©ation SQL via LLM avec contexte
8. **Validation** : Framework + sÃ©curitÃ© + sÃ©mantique
9. **Cache** : Stockage rÃ©sultat (si succÃ¨s)
10. **RÃ©ponse** : Retour formatÃ© avec mÃ©tadonnÃ©es

## ğŸ§ª Tests

```bash
# Installation des dÃ©pendances de test
pip install pytest pytest-asyncio httpx

# Lancer les tests
pytest tests/ -v

# Tests avec couverture
pytest tests/ --cov=app --cov-report=html
```

## ğŸ“Š Monitoring & MÃ©triques

### Endpoints de Monitoring

- **Health Check** : `/api/v1/health`
- **Status Services** : Pinecone, LLM, Redis, Embedding

### Logs StructurÃ©s

```python
# Exemple de log
2024-01-15 10:30:45 - nl2sql.translator - INFO - Traduction terminÃ©e en 2.340s (statut: success, framework: conforme, provider: openai)
```

### MÃ©triques Disponibles

- Temps de traitement par requÃªte
- Taux de cache hit/miss
- Distribution par provider LLM
- Taux de conformitÃ© framework

## ğŸš€ DÃ©ploiement Production

### Docker Compose (RecommandÃ©)

```yaml
version: '3.8'
services:
  api:
    image: nl2sql-api:latest
    environment:
      - PINECONE_API_KEY=${PINECONE_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - REDIS_URL=redis://redis:6379/0
    depends_on:
      - redis
  
  redis:
    image: redis:alpine
    command: redis-server --appendonly yes
    volumes:
      - redis-data:/data

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
```

### Variables pour Production

```env
DEBUG=false
CACHE_ENABLED=true
METRICS_ENABLED=true
API_KEY=generate_strong_secret
ALLOWED_HOSTS=["your-domain.com","api.your-domain.com"]
```

## â“ FAQ

<details>
<summary><b>Comment l'API Ã©vite-t-elle la pollution de ma base vectorielle ?</b></summary>

L'API ne stocke **JAMAIS** automatiquement de nouvelles requÃªtes dans Pinecone. Elle utilise uniquement la base existante pour la recherche sÃ©mantique. Le stockage peut Ãªtre activÃ© manuellement si nÃ©cessaire.

</details>

<details>
<summary><b>Quels sont les providers LLM supportÃ©s ?</b></summary>

- **OpenAI** : GPT-4o, GPT-4 Turbo, GPT-4, GPT-3.5 Turbo
- **Anthropic** : Claude 3 Opus, Claude 3 Sonnet, Claude 3 Haiku  
- **Google** : Gemini Pro, Gemini 1.5 Pro, Gemini 1.5 Flash

</details>

<details>
<summary><b>Comment fonctionne le framework de sÃ©curitÃ© ?</b></summary>

Chaque requÃªte gÃ©nÃ©rÃ©e DOIT inclure :
1. Filtre `WHERE depot.ID_USER = ?` pour la sÃ©curitÃ©
2. Table DEPOT pour les autorisations  
3. Hashtags appropriÃ©s pour la gestion des permissions

Si une requÃªte n'est pas conforme, l'API tente une correction automatique.

</details>

<details>
<summary><b>Le cache Redis est-il obligatoire ?</b></summary>

Non, Redis est optionnel. Sans Redis :
- Les performances seront lÃ©gÃ¨rement impactÃ©es
- Chaque requÃªte sera retraitÃ©e complÃ¨tement
- La limitation de dÃ©bit utilisera une mÃ©moire interne
</details>

<details>
<summary><b>Comment personnaliser le schÃ©ma de base de donnÃ©es ?</b></summary>

1. CrÃ©ez votre fichier `.sql` ou `.md` dans `app/schemas/`
2. Modifiez `SCHEMA_PATH` dans votre `.env`
3. RedÃ©marrez l'application

Le schÃ©ma peut Ãªtre en SQL standard ou en Markdown documentÃ©.

</details>

## ğŸ¤ Contribution

Les contributions sont bienvenues ! Voir [CONTRIBUTING.md](CONTRIBUTING.md) pour les guidelines.

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir [LICENSE](LICENSE) pour plus de dÃ©tails.

## ğŸ“ Support

- **Organisation** : [Datasulting](https://datasulting.com)
- **Email** : support@datasulting.com
- **Documentation** : [Wiki du projet](../../wiki)

---

<div align="center">
<p>âœ¨ <strong>NL2SQL API - Transformez vos questions en requÃªtes SQL intelligentes</strong> âœ¨</p>
<p>DÃ©veloppÃ© avec â¤ï¸ par <a href="https://datasulting.com">Datasulting</a></p>
<p><em>Version 2.0.0 - Support Multi-LLM & Recherche Vectorielle AvancÃ©e</em></p>
</div>