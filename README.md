# ğŸš€ NL2SQL API

<div align="center">

![NL2SQL Logo](https://img.shields.io/badge/NL2SQL-API-blue?style=for-the-badge&logo=database&logoColor=white)

[![FastAPI](https://img.shields.io/badge/FastAPI-005571?style=flat-square&logo=fastapi)](https://fastapi.tiangolo.com/)
[![Multi-LLM](https://img.shields.io/badge/Multi--LLM-OpenAI|Anthropic|Google-orange?style=flat-square)](https://openai.com/)
[![Pinecone](https://img.shields.io/badge/Pinecone-Vector_DB-black?style=flat-square)](https://www.pinecone.io/)
[![Python 3.8+](https://img.shields.io/badge/Python-3.8+-blue?style=flat-square&logo=python&logoColor=white)](https://www.python.org/)
[![Docker](https://img.shields.io/badge/Docker-Ready-2496ED?style=flat-square&logo=docker&logoColor=white)](https://www.docker.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg?style=flat-square)](https://opensource.org/licenses/MIT)

_API intelligente qui traduit vos questions en langage naturel en requÃªtes SQL optimisÃ©es avec recherche vectorielle sÃ©mantique, support multi-LLM et prompts Jinja2 modulaires_

[ğŸš€ Installation](#-installation) â€¢ [ğŸ’» Utilisation](#-utilisation) â€¢ [ğŸ›¡ï¸ SÃ©curitÃ©](#%EF%B8%8F-architecture-de-sÃ©curitÃ©) â€¢ [âš™ï¸ Configuration](#%EF%B8%8F-configuration) â€¢ [â“ FAQ](#-faq)

</div>

---

## âœ¨ FonctionnalitÃ©s ClÃ©s

- ğŸ§  **Multi-LLM** - Support OpenAI (GPT-4o), Anthropic (Claude), Google (Gemini)
- ğŸ” **Recherche SÃ©mantique** - Utilise Pinecone pour trouver des requÃªtes similaires
- ğŸ›¡ï¸ **SÃ©curitÃ© RenforcÃ©e** - Framework obligatoire avec filtres utilisateur automatiques
- âš¡ **Cache Intelligent** - Redis avec contrÃ´le granulaire par requÃªte
- ğŸ“‹ **Validation AvancÃ©e** - Service unifiÃ© : syntaxe, sÃ©curitÃ©, framework et sÃ©mantique
- ğŸ“š **Documentation Interactive** - Swagger UI et ReDoc intÃ©grÃ©s
- ğŸ³ **ConteneurisÃ©** - DÃ©ploiement avec Docker et Docker Compose
- ğŸ”§ **Configurable** - Variables d'environnement pour tous les paramÃ¨tres
- ğŸ“Š **Monitoring** - MÃ©triques de performance et logs dÃ©taillÃ©s
- ğŸ¯ **Prompts Jinja2** - Templates modulaires et personnalisables avec contexte dynamique

## ğŸ—ï¸ Architecture

```mermaid
graph TB
    A[RequÃªte NL] --> B[Validation EntrÃ©e]
    B --> C[VÃ©rification Pertinence RH]
    C --> D[Vectorisation Google]
    D --> E{Cache Hit?}
    E -->|Oui| F[Retour Cache]
    E -->|Non| G[Recherche Pinecone]
    G --> H{Correspondance Exacte?}
    H -->|Oui| I[Validation Framework]
    H -->|Non| J[GÃ©nÃ©ration LLM + Prompts Jinja2]
    J --> K[Validation ComplÃ¨te]
    K --> L[Correction Auto si NÃ©cessaire]
    L --> M[GÃ©nÃ©ration Explication]
    M --> N[Mise en Cache]
    I --> N
    N --> O[RÃ©ponse avec RequÃªtes Similaires]
```

## ğŸš€ Installation

### PrÃ©requis

- Python 3.8+
- ClÃ©s API pour au moins un LLM provider
- ClÃ© API Pinecone
- Redis (optionnel, pour le cache)
- Docker & Docker Compose (optionnel)

### ğŸ”§ Installation Standard

1. **Cloner le repository**
   ```bash
   git clone https://github.com/datasulting/nl2sql-api.git
   cd nl2sql-api
   ```

2. **CrÃ©er l'environnement virtuel**
   ```bash
   python -m venv venv
   source venv/bin/activate  # Linux/macOS
   venv\Scripts\activate     # Windows
   ```

3. **Installer les dÃ©pendances**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configuration**
   ```bash
   cp .env.example .env
   ```
   
   Ã‰ditez `.env` avec vos clÃ©s API :
   ```env
   # Obligatoire
   PINECONE_API_KEY=your_key_here
   OPENAI_API_KEY=your_key_here
   
   # Optionnel pour multi-LLM
   ANTHROPIC_API_KEY=your_key_here
   GOOGLE_API_KEY=your_key_here
   
   # Configuration base
   PINECONE_INDEX_NAME=kpi-to-sql-gemini
   DEFAULT_PROVIDER=openai
   EMBEDDING_MODEL=text-embedding-004
   EMBEDDING_PROVIDER=google
   ```

5. **Ajouter votre schÃ©ma**
   ```bash
   mkdir -p app/schemas
   # Copier votre fichier de schÃ©ma SQL/Markdown
   cp your-schema.md app/schemas/
   ```

6. **Lancer l'application**
   ```bash
   python -m app.main
   ```

### ğŸ³ Installation avec Docker

1. **PrÃ©parer la configuration**
   ```bash
   git clone https://github.com/datasulting/nl2sql-api.git
   cd nl2sql-api
   cp .env.example .env
   # Ã‰diter .env avec vos clÃ©s
   ```

2. **Lancer avec Docker Compose**
   ```bash
   docker-compose up -d
   ```

L'API sera accessible sur http://localhost:8000

## ğŸ’» Utilisation

### ğŸ“– Documentation Interactive

- **Swagger UI** : http://localhost:8000/docs
- **ReDoc** : http://localhost:8000/redoc

### ğŸ”„ Endpoint Principal : `/api/v1/translate`

```bash
curl -X POST "http://localhost:8000/api/v1/translate" \
  -H "Content-Type: application/json" \
  -H "X-API-Key: your_api_key" \
  -d '{
    "query": "Quel est l'Ã¢ge moyen de mes collaborateurs ?",
    "provider": "openai",
    "model": "gpt-4o",
    "explain": true,
    "use_cache": true,
    "include_similar_details": true
  }'
```

### ğŸ“‹ ParamÃ¨tres Disponibles

| ParamÃ¨tre | Type | DÃ©faut | Description |
|-----------|------|--------|-------------|
| `query` | string | **requis** | Question en langage naturel |
| `provider` | string | `openai` | LLM Ã  utiliser (`openai`, `anthropic`, `google`) |
| `model` | string | auto | ModÃ¨le spÃ©cifique (ex: `gpt-4o`, `claude-3-opus-20240229`) |
| `validate` | boolean | `true` | Valider la requÃªte SQL gÃ©nÃ©rÃ©e |
| `explain` | boolean | `true` | Fournir une explication |
| `use_cache` | boolean | `true` | Utiliser le cache Redis |
| `include_similar_details` | boolean | `false` | Inclure les dÃ©tails des vecteurs similaires |
| `schema_path` | string | auto | Chemin du schÃ©ma (optionnel) |
| `user_id_placeholder` | string | `"?"` | Placeholder pour l'ID utilisateur |

### ğŸ¯ Exemples d'Utilisation

<details>
<summary><b>Exemple avec Python</b></summary>

```python
import requests

url = "http://localhost:8000/api/v1/translate"
headers = {
    "Content-Type": "application/json",
    "X-API-Key": "your_api_key"
}

# RequÃªte simple
response = requests.post(url, headers=headers, json={
    "query": "Combien d'employÃ©s en CDI ?",
    "provider": "openai"
})

result = response.json()
print(f"SQL: {result['sql']}")
print(f"Explication: {result['explanation']}")

# RequÃªte avancÃ©e avec dÃ©tails des vecteurs similaires
response = requests.post(url, headers=headers, json={
    "query": "Top 10 des salaires les plus Ã©levÃ©s en 2023",
    "provider": "anthropic",
    "model": "claude-3-opus-20240229",
    "use_cache": False,
    "include_similar_details": True
})
```

</details>

<details>
<summary><b>RÃ©ponse Type avec RequÃªtes Similaires</b></summary>

```json
{
  "query": "Quel est l'Ã¢ge moyen de mes collaborateurs ?",
  "sql": "SELECT ROUND(AVG(TRUNCATE(b.AGE, 0)), 2) AS Age_Moyen FROM depot a INNER JOIN facts b ON a.ID = b.ID_NUMDEPOT WHERE a.ID_USER = ? AND (b.FIN_CONTRAT = 'null' OR b.FIN_CONTRAT > a.datefin); #DEPOT_a# #FACTS_b# #PERIODE#",
  "valid": true,
  "validation_message": "Validation complÃ¨te rÃ©ussie",
  "explanation": "Cette requÃªte calcule l'Ã¢ge moyen des collaborateurs encore en contrat.",
  "is_exact_match": false,
  "status": "success",
  "processing_time": 8.979,
  "similar_queries_details": [
    {
      "score": 0.724,
      "texte_complet": "Age moyen par Ã©tablissement",
      "requete": "SELECT ROUND(AVG(b.AGE), 2) FROM depot a INNER JOIN facts b...",
      "id": "gemini_load_1748246903_1381"
    }
  ],
  "framework_compliant": true,
  "from_cache": false,
  "provider": "openai",
  "model": "gpt-4o"
}
```

</details>

### ğŸ›¡ï¸ Autres Endpoints

| Endpoint | MÃ©thode | Description |
|----------|---------|-------------|
| `/api/v1/health` | GET | Ã‰tat de santÃ© des services |
| `/api/v1/models` | GET | ModÃ¨les LLM disponibles |
| `/api/v1/schemas` | GET | SchÃ©mas SQL disponibles |
| `/api/v1/validate-framework` | POST | Validation framework d'une requÃªte |
| `/api/v1/prompts/templates` | GET | Templates de prompts Jinja2 |
| `/api/v1/cache/stats` | GET | Statistiques du cache Redis |

## ğŸ›¡ï¸ Architecture de SÃ©curitÃ©

### Framework Obligatoire

Chaque requÃªte SQL gÃ©nÃ©rÃ©e **DOIT OBLIGATOIREMENT** respecter :

1. **Filtre Utilisateur** : `WHERE [alias_depot].ID_USER = ?`
2. **Table DEPOT** : Toujours prÃ©sente pour les autorisations multi-tenant
3. **Hashtags** : `#DEPOT_[alias]#` minimum + contextuels (#PERIODE#, #FACTS_[alias]#)
4. **Lecture Seule** : Uniquement SELECT (pas d'INSERT/UPDATE/DELETE)

### Exemple de RequÃªte Conforme

```sql
SELECT b.NOM, b.PRENOM, ROUND(AVG(b.AGE), 2) AS AGE_MOYEN
FROM depot a 
INNER JOIN facts b ON a.ID = b.ID_NUMDEPOT  
WHERE a.ID_USER = ? 
  AND (b.FIN_CONTRAT = 'null' OR b.FIN_CONTRAT > a.datefin)
  AND CONCAT(SUBSTRING(a.periode, 5, 4), SUBSTRING(a.periode, 3, 2)) IN (
    SELECT MAX(CONCAT(SUBSTRING(w.periode, 5, 4), SUBSTRING(w.periode, 3, 2)))
    FROM depot w
    WHERE w.periode IN (#PERIODE#)
    AND w.id_user = a.id_user
  )
GROUP BY b.NOM, b.PRENOM
ORDER BY AGE_MOYEN DESC;
#DEPOT_a# #FACTS_b# #PERIODE#
```

### Validation Multi-Niveaux

Le `ValidationService` effectue une validation complÃ¨te :

1. âœ… **Validation Syntaxique** - Structure SQL correcte
2. âœ… **Validation SÃ©curitÃ©** - Pas d'opÃ©rations destructives
3. âœ… **Validation Framework** - Respect des rÃ¨gles obligatoires
4. âœ… **Validation SÃ©mantique** - Correspondance avec la demande (LLM)
5. âœ… **Correction Automatique** - Auto-fix si framework non conforme

## âš™ï¸ Configuration

### Variables d'Environnement

#### ğŸ”‘ API Keys (Obligatoires)

```env
PINECONE_API_KEY=your_pinecone_key
OPENAI_API_KEY=your_openai_key
ANTHROPIC_API_KEY=your_anthropic_key  # Optionnel
GOOGLE_API_KEY=your_google_key        # Optionnel
```

#### ğŸ¤– Configuration LLM

```env
DEFAULT_PROVIDER=openai               # openai, anthropic, google
DEFAULT_OPENAI_MODEL=gpt-4o
DEFAULT_ANTHROPIC_MODEL=claude-3-opus-20240229
DEFAULT_GOOGLE_MODEL=gemini-pro
LLM_TEMPERATURE=0.2
LLM_TIMEOUT=30
```

#### ğŸ” Configuration Embedding et Recherche

```env
# Embedding Google (nouveau)
EMBEDDING_MODEL=text-embedding-004    # Google text-embedding-004
EMBEDDING_PROVIDER=google             # google (par dÃ©faut)
EMBEDDING_DIMENSIONS=768              # 768 pour text-embedding-004

# Recherche vectorielle
EXACT_MATCH_THRESHOLD=0.95            # Seuil correspondance exacte
TOP_K_RESULTS=5                       # Nombre rÃ©sultats similaires
SCHEMA_PATH=app/schemas/datasulting.md
```

#### ğŸ—„ï¸ Configuration Pinecone

```env
PINECONE_INDEX_NAME=kpi-to-sql-gemini # Nom de votre index
PINECONE_ENVIRONMENT=gcp-starter      # Environnement Pinecone
```

#### ğŸ—„ï¸ Configuration Cache Redis

```env
REDIS_URL=redis://localhost:6379/0
REDIS_TTL=3600                # DurÃ©e cache (secondes)
CACHE_ENABLED=true
```

#### ğŸ” Configuration SÃ©curitÃ©

```env
API_KEY=your_secret_api_key   # Authentification (optionnel)
API_KEY_NAME=X-API-Key
ALLOWED_HOSTS=["*","localhost","127.0.0.1"]
DEBUG=false
```

## ğŸ”§ Architecture du Projet - Service Layer Pattern

```
nl2sql-api/
â”œâ”€â”€ app/                      # Code source principal
â”‚   â”œâ”€â”€ api/                  # Couche API (FastAPI)
â”‚   â”‚   â”œâ”€â”€ models.py         # ModÃ¨les Pydantic avec SimilarQueryDetail
â”‚   â”‚   â””â”€â”€ routes.py         # Endpoints avec gestion d'erreurs centralisÃ©e
â”‚   â”œâ”€â”€ services/             # ğŸ†• COUCHE SERVICE LAYER
â”‚   â”‚   â”œâ”€â”€ translation_service.py  # Service principal NL2SQL
â”‚   â”‚   â””â”€â”€ validation_service.py   # Service unifiÃ© de validation
â”‚   â”œâ”€â”€ core/                 # Couche mÃ©tier
â”‚   â”‚   â”œâ”€â”€ llm_factory.py    # Factory Pattern pour Multi-LLM
â”‚   â”‚   â”œâ”€â”€ llm_providers.py  # Providers OpenAI/Anthropic/Google
â”‚   â”‚   â”œâ”€â”€ llm_service.py    # Service LLM unifiÃ©
â”‚   â”‚   â”œâ”€â”€ embedding.py      # Google text-embedding-004
â”‚   â”‚   â”œâ”€â”€ vector_search.py  # Pinecone avec gestion ScoredVector
â”‚   â”‚   â”œâ”€â”€ http_client.py    # Client HTTP avec retry automatique
â”‚   â”‚   â””â”€â”€ exceptions.py     # Exceptions centralisÃ©es
â”‚   â”œâ”€â”€ prompts/              # ğŸ†• SYSTÃˆME DE PROMPTS JINJA2
â”‚   â”‚   â”œâ”€â”€ prompt_manager.py # Gestionnaire central des prompts
â”‚   â”‚   â”œâ”€â”€ sql_generation.j2 # Templates de gÃ©nÃ©ration SQL
â”‚   â”‚   â””â”€â”€ sql_validation.j2 # Templates de validation
â”‚   â”œâ”€â”€ utils/                # Utilitaires
â”‚   â”‚   â”œâ”€â”€ cache.py          # Redis avec exceptions
â”‚   â”‚   â”œâ”€â”€ cache_decorator.py # DÃ©corateur @cache_service_method
â”‚   â”‚   â”œâ”€â”€ schema_loader.py  # Chargement schÃ©mas
â”‚   â”‚   â””â”€â”€ validators.py     # Validations (deprecated â†’ ValidationService)
â”‚   â”œâ”€â”€ schemas/              # SchÃ©mas SQL/MD
â”‚   â”‚   â””â”€â”€ datasulting.md    # SchÃ©ma RH avec exemples
â”‚   â”œâ”€â”€ config.py             # Configuration Pydantic
â”‚   â”œâ”€â”€ dependencies.py       # DÃ©pendances FastAPI
â”‚   â”œâ”€â”€ security.py          # Middlewares sÃ©curitÃ©
â”‚   â””â”€â”€ main.py              # Point d'entrÃ©e avec Service Layer
â”œâ”€â”€ docker/                  # Configuration Docker
â”œâ”€â”€ tests/                   # Tests unitaires
â”œâ”€â”€ .env.example            # Template configuration
â”œâ”€â”€ requirements.txt        # DÃ©pendances Python
â””â”€â”€ README.md
```

## ğŸ”„ Flux de Traduction Complet - Service Layer

1. **RÃ©ception API** : Validation requÃªte utilisateur (`routes.py`)
2. **Service de Traduction** : `TranslationService.translate()` orchestrateur principal
3. **Validation d'EntrÃ©e** : `ValidationService.validate_user_input()`
4. **Pertinence RH** : VÃ©rification via LLM Factory
5. **Cache Check** : DÃ©corateur `@cache_service_method`
6. **Embedding** : Google `text-embedding-004` (768 dimensions)
7. **Recherche Vectorielle** : Pinecone avec gestion `ScoredVector`
8. **Correspondance Exacte** : Seuil configurable (0.95)
9. **GÃ©nÃ©ration LLM** : Via prompts Jinja2 avec contexte dynamique
10. **Validation ComplÃ¨te** : `ValidationService.validate_complete()`
11. **Correction Auto** : Framework compliance si nÃ©cessaire
12. **Explication** : GÃ©nÃ©ration via LLM avec prompts spÃ©cialisÃ©s
13. **Cache Storage** : Stockage rÃ©sultat si succÃ¨s
14. **RÃ©ponse Enrichie** : Avec `similar_queries_details` et mÃ©tadonnÃ©es

## ğŸ§ª Tests

```bash
# Installation des dÃ©pendances de test
pip install pytest pytest-asyncio httpx

# Lancer les tests
pytest tests/ -v

# Tests avec couverture
pytest tests/ --cov=app --cov-report=html
```

## ğŸ“Š Monitoring & MÃ©triques

### Endpoints de Monitoring

- **Health Check** : `/api/v1/health` - Ã‰tat de tous les services
- **Service Debug** : `/api/v1/debug/service-status` (mode debug uniquement)
- **Prompts Status** : `/api/v1/prompts/health` - Ã‰tat systÃ¨me Jinja2

### Logs StructurÃ©s - Service Layer

```python
# Exemple de log
2025-05-30 09:20:26 - app.services.translation_service - INFO - Traduction terminÃ©e en 9.524s (statut: success, framework: conforme, vecteurs similaires: 5)
```

### MÃ©triques Disponibles

- Temps de traitement par requÃªte
- Taux de cache hit/miss Redis
- Distribution par provider LLM
- Taux de conformitÃ© framework
- QualitÃ© des vecteurs similaires (scores)

## ğŸš€ DÃ©ploiement Production

### Docker Compose (RecommandÃ©)

```yaml
version: '3.8'
services:
  api:
    image: nl2sql-api:latest
    environment:
      - PINECONE_API_KEY=${PINECONE_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
      - REDIS_URL=redis://redis:6379/0
      - EMBEDDING_MODEL=text-embedding-004
      - EMBEDDING_PROVIDER=google
    depends_on:
      - redis
  
  redis:
    image: redis:alpine
    command: redis-server --appendonly yes
    volumes:
      - redis-data:/data

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf

volumes:
  redis-data:
```

### Variables pour Production

```env
DEBUG=false
CACHE_ENABLED=true
METRICS_ENABLED=true
API_KEY=generate_strong_secret
ALLOWED_HOSTS=["your-domain.com","api.your-domain.com"]
EMBEDDING_MODEL=text-embedding-004
EMBEDDING_PROVIDER=google
```

## â“ FAQ

<details>
<summary><b>Comment l'API Ã©vite-t-elle la pollution de ma base vectorielle ?</b></summary>

L'API ne stocke **JAMAIS** automatiquement de nouvelles requÃªtes dans Pinecone. Elle utilise uniquement la base existante pour la recherche sÃ©mantique. Le stockage peut Ãªtre activÃ© manuellement si nÃ©cessaire via le paramÃ¨tre `store_result=True`.

</details>

<details>
<summary><b>Quels sont les providers LLM supportÃ©s et leurs modÃ¨les ?</b></summary>

- **OpenAI** : GPT-4o, GPT-4o Mini, GPT-4 Turbo, GPT-4, GPT-3.5 Turbo
- **Anthropic** : Claude 3 Opus, Claude 3 Sonnet, Claude 3 Haiku, Claude 3.5 Sonnet
- **Google** : Gemini Pro, Gemini 1.5 Pro, Gemini 1.5 Flash

</details>

<details>
<summary><b>Comment fonctionne le nouveau systÃ¨me d'embedding Google ?</b></summary>

L'API utilise maintenant **Google text-embedding-004** (768 dimensions) au lieu de Sentence Transformers. Cela offre :
- Meilleure qualitÃ© de vectorisation
- Pas de modÃ¨le local Ã  tÃ©lÃ©charger
- CompatibilitÃ© avec l'Ã©cosystÃ¨me Google AI

</details>

<details>
<summary><b>Que sont les "similar_queries_details" dans la rÃ©ponse ?</b></summary>

C'est une nouvelle fonctionnalitÃ© qui retourne les dÃ©tails complets des 5 vecteurs les plus similaires trouvÃ©s dans Pinecone :
```json
"similar_queries_details": [
  {
    "score": 0.724,
    "texte_complet": "Age moyen par Ã©tablissement", 
    "requete": "SELECT ROUND(AVG(b.AGE), 2)...",
    "id": "gemini_load_1748246903_1381"
  }
]
```

</details>

<details>
<summary><b>Comment fonctionne le systÃ¨me de prompts Jinja2 ?</b></summary>

Les prompts sont maintenant modulaires et personnalisables :
1. **Templates** : `sql_generation.j2`, `sql_validation.j2`
2. **Contexte dynamique** : pÃ©riode, dÃ©partement, mode strict
3. **Macros rÃ©utilisables** : `system_message()`, `generate_sql_prompt()`
4. **Fallback automatique** : si Jinja2 Ã©choue, utilise prompts par dÃ©faut

</details>

<details>
<summary><b>Le cache Redis est-il obligatoire ?</b></summary>

Non, Redis est optionnel. Sans Redis :
- Les performances seront lÃ©gÃ¨rement impactÃ©es
- Chaque requÃªte sera retraitÃ©e complÃ¨tement
- La limitation de dÃ©bit utilisera une mÃ©moire interne
- Les logs indiqueront "Redis non disponible, le cache sera dÃ©sactivÃ©"
</details>

<details>
<summary><b>Comment personnaliser le schÃ©ma de base de donnÃ©es ?</b></summary>

1. CrÃ©ez votre fichier `.sql` ou `.md` dans `app/schemas/`
2. Modifiez `SCHEMA_PATH` dans votre `.env`
3. RedÃ©marrez l'application

Le schÃ©ma peut Ãªtre en SQL standard ou en Markdown documentÃ© avec exemples.

</details>

## ğŸ†• NouveautÃ©s v2.0.0

### **Architecture Service Layer**
- âœ… `TranslationService` : Orchestrateur principal
- âœ… `ValidationService` : Validation unifiÃ©e 
- âœ… Factory Pattern pour Multi-LLM
- âœ… Exceptions centralisÃ©es

### **SystÃ¨me de Prompts Jinja2**
- âœ… Templates modulaires (`sql_generation.j2`, `sql_validation.j2`)
- âœ… Contexte dynamique (pÃ©riode, dÃ©partement, mode strict)
- âœ… Fallback automatique vers prompts par dÃ©faut

### **Embedding Google**
- âœ… `text-embedding-004` (768 dimensions)
- âœ… Plus de dÃ©pendance Sentence Transformers
- âœ… Meilleure qualitÃ© de vectorisation

### **Recherche Vectorielle AmÃ©liorÃ©e**
- âœ… Support objets `ScoredVector` de Pinecone
- âœ… `similar_queries_details` avec score, texte complet, requÃªte SQL et ID
- âœ… Normalisation automatique des mÃ©tadonnÃ©es

### **Cache et Performance**
- âœ… DÃ©corateur `@cache_service_method` pour services
- âœ… ContrÃ´le granulaire par requÃªte (`use_cache`)
- âœ… MÃ©triques de performance dÃ©taillÃ©es

## ğŸ¤ Contribution

Les contributions sont bienvenues ! Voir [CONTRIBUTING.md](CONTRIBUTING.md) pour les guidelines.

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir [LICENSE](LICENSE) pour plus de dÃ©tails.

## ğŸ“ Support

- **Organisation** : [Datasulting](https://datasulting.com)
- **Email** : support@datasulting.com
- **Documentation** : [Wiki du projet](../../wiki)

---

<div align="center">
<p>âœ¨ <strong>NL2SQL API v2.0.0 - Architecture Service Layer avec Prompts Jinja2</strong> âœ¨</p>
<p>DÃ©veloppÃ© avec â¤ï¸ par <a href="https://datasulting.com">Datasulting</a></p>
<p><em>Version 2.0.0 - Service Layer + Multi-LLM + Prompts Modulaires + Google Embedding</em></p>
</div>